{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ba0e72a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fooli\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\fooli\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\transformers\\utils\\generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\fooli\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\Users\\fooli\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import urllib3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from filelock import FileLock\n",
    "from prettytable import PrettyTable\n",
    "from typing import TYPE_CHECKING, Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertPreTrainedModel,\n",
    "    BertModel,\n",
    "    BertConfig\n",
    ")\n",
    "from transformers.file_utils import (\n",
    "    add_start_docstrings,\n",
    "    add_start_docstrings_to_model_forward,\n",
    "    add_code_sample_docstrings,\n",
    "    add_code_sample_docstrings\n",
    ")\n",
    "from transformers.modeling_outputs import (\n",
    "    SequenceClassifierOutput\n",
    ")\n",
    "from transformers.trainer import Trainer,TrainingArguments\n",
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd249d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set path to SentEval\n",
    "PATH_TO_SENTEVAL = os.getcwd()+'/SentEval-main'\n",
    "PATH_TO_DATA =  os.getcwd()+'/SentEval-main/data'\n",
    "\n",
    "# Import SentEval\n",
    "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "import senteval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48724641",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95b1c28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "train_dataset = load_from_disk(\"wiki_for_sts_32\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2910899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model in all STS tasks\n",
    "def print_table(task_names, scores):\n",
    "    tb = PrettyTable()\n",
    "    tb.field_names = task_names\n",
    "    tb.add_row(scores)\n",
    "    print(tb)\n",
    "    \n",
    "def evalModel(model,tokenizer, pooler): \n",
    "    tasks = ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']\n",
    "    \n",
    "    params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\n",
    "    params['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n",
    "                                'tenacity': 3, 'epoch_size': 2}\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def prepare(params, samples):\n",
    "        return\n",
    "\n",
    "    def batcher(params, batch, max_length=None):\n",
    "            # Handle rare token encoding issues in the dataset\n",
    "            if len(batch) >= 1 and len(batch[0]) >= 1 and isinstance(batch[0][0], bytes):\n",
    "                batch = [[word.decode('utf-8') for word in s] for s in batch]\n",
    "\n",
    "            sentences = [' '.join(s) for s in batch]\n",
    "            \n",
    "            batch = tokenizer.batch_encode_plus(\n",
    "                sentences,\n",
    "                return_tensors='pt',\n",
    "                padding=True,\n",
    "                max_length=max_length,\n",
    "                truncation=True\n",
    "            )\n",
    "            # Move to the correct device\n",
    "            for k in batch:\n",
    "                batch[k] = batch[k].to(device)\n",
    "            \n",
    "            # Get raw embeddings\n",
    "            with torch.no_grad():\n",
    "                pooler_output = model(**batch, output_hidden_states=True, return_dict=True)\n",
    "                if pooler == \"cls_before_pooler\":\n",
    "                    pooler_output = pooler_output.last_hidden_state[:, 0]\n",
    "                elif pooler == \"cls_after_pooler\":\n",
    "                    pooler_output = pooler_output.pooler_output\n",
    "\n",
    "            return pooler_output.cpu()\n",
    "    results = {}\n",
    "\n",
    "    for task in tasks:\n",
    "        se = senteval.engine.SE(params, batcher, prepare)\n",
    "        result = se.eval(task)\n",
    "        results[task] = result\n",
    "    task_names = []\n",
    "    scores = []\n",
    "    for task in ['STS12', 'STS13', 'STS14', 'STS15', 'STS16', 'STSBenchmark', 'SICKRelatedness']:\n",
    "        task_names.append(task)\n",
    "        if task in results:\n",
    "            if task in ['STS12', 'STS13', 'STS14', 'STS15', 'STS16']:\n",
    "                #print(f\"task {task} results[task] {results[task]}\")\n",
    "                scores.append(\"%.2f\" % (results[task]['all']['spearman']['mean'] * 100))\n",
    "            else:\n",
    "                print(f\"task {task} results[task] {results[task]}\")\n",
    "                scores.append(\"%.2f\" % (results[task]['spearman'] * 100))\n",
    "        else:\n",
    "            scores.append(\"0.00\")\n",
    "    task_names.append(\"Avg.\")\n",
    "    scores.append(\"%.2f\" % (sum([float(score) for score in scores]) / len(scores)))\n",
    "    print_table(task_names, scores)\n",
    "\n",
    "    return sum([float(score) for score in scores])/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4001ccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Head for getting sentence representations over RoBERTa/BERT's CLS representation.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, features, **kwargs):\n",
    "        x = self.dense(features)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Similarity(nn.Module):\n",
    "    \"\"\"\n",
    "    Dot product or cosine similarity\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, temp):\n",
    "        super().__init__()\n",
    "        self.temp = temp\n",
    "        self.cos = nn.CosineSimilarity(dim=-1)\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.cos(x, y) / self.temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7225cd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a6bbc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc text needed for transformers model\n",
    "\n",
    "_CHECKPOINT_FOR_DOC = \"bert-base-uncased\"\n",
    "_CONFIG_FOR_DOC = \"BertConfig\"\n",
    "_TOKENIZER_FOR_DOC = \"BertTokenizer\"\n",
    "\n",
    "\n",
    "BERT_START_DOCSTRING = r\"\"\"\n",
    "\n",
    "    This model inherits from :class:`~transformers.PreTrainedModel`. Check the superclass documentation for the generic\n",
    "    methods the library implements for all its model (such as downloading or saving, resizing the input embeddings,\n",
    "    pruning heads etc.)\n",
    "\n",
    "    This model is also a PyTorch `torch.nn.Module <https://pytorch.org/docs/stable/nn.html#torch.nn.Module>`__\n",
    "    subclass. Use it as a regular PyTorch Module and refer to the PyTorch documentation for all matter related to\n",
    "    general usage and behavior.\n",
    "headlines\n",
    "    Parameters:\n",
    "        config (:class:`~transformers.BertConfig`): Model configuration class with all the parameters of the model.\n",
    "            Initializing with a config file does not load the weights associated with the model, only the\n",
    "            configuration. Check out the :meth:`~transformers.PreTrainedModel.from_pretrained` method to load the model\n",
    "            weights.\n",
    "\"\"\"\n",
    "\n",
    "BERT_INPUTS_DOCSTRING = r\"\"\"\n",
    "    Args:\n",
    "        input_ids (:obj:`torch.LongTensor` of shape :obj:`({0})`):\n",
    "            Indices of input sequence tokens in the vocabulary.\n",
    "\n",
    "            Indices can be obtained using :class:`~transformers.BertTokenizer`. See\n",
    "            :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__` for\n",
    "            details.\n",
    "\n",
    "            `What are input IDs? <../glossary.html#input-ids>`__\n",
    "        attention_mask (:obj:`torch.FloatTensor` of shape :obj:`({0})`, `optional`):\n",
    "            Mask to avoid performing attention on padding token indices. Mask values selected in ``[0, 1]``:\n",
    "\n",
    "            - 1 for tokens that are **not masked**,\n",
    "            - 0 for tokens that are **masked**.\n",
    "\n",
    "            `What are attention masks? <../glossary.html#attention-mask>`__\n",
    "        token_type_ids (:obj:`torch.LongTensor` of shape :obj:`({0})`, `optional`):\n",
    "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in ``[0,\n",
    "            1]``:\n",
    "\n",
    "            - 0 corresponds to a `sentence A` token,\n",
    "            - 1 corresponds to a `sentence B` token.\n",
    "\n",
    "            `What are token type IDs? <../glossary.html#token-type-ids>`_\n",
    "        position_ids (:obj:`torch.LongTensor` of shape :obj:`({0})`, `optional`):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range ``[0,\n",
    "            config.max_position_embeddings - 1]``.\n",
    "\n",
    "            `What are position IDs? <../glossary.html#position-ids>`_\n",
    "        head_mask (:obj:`torch.FloatTensor` of shape :obj:`(num_heads,)` or :obj:`(num_layers, num_heads)`, `optional`):\n",
    "            Mask to nullify selected heads of the self-attention modules. Mask values selected in ``[0, 1]``:\n",
    "\n",
    "            - 1 indicates the head is **not masked**,\n",
    "            - 0 indicates the head is **masked**.\n",
    "\n",
    "        inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`({0}, hidden_size)`, `optional`):\n",
    "            Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded representation.\n",
    "            This is useful if you want more control over how to convert :obj:`input_ids` indices into associated\n",
    "            vectors than the model's internal embedding lookup matrix.\n",
    "        output_attentions (:obj:`bool`, `optional`):\n",
    "            Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under returned\n",
    "            tensors for more detail.\n",
    "        output_hidden_states (:obj:`bool`, `optional`):\n",
    "            Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors for\n",
    "            more detail.\n",
    "        return_dict (:obj:`bool`, `optional`):\n",
    "            Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "510db08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement of SimCSEModel\n",
    "\n",
    "@add_start_docstrings(\n",
    "    \"\"\"\n",
    "    Bert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled\n",
    "    output) e.g. for GLUE tasks.\n",
    "    \"\"\",\n",
    "    BERT_START_DOCSTRING,\n",
    ")\n",
    "class SimCSEModel(BertPreTrainedModel):\n",
    "    def __init__(self, config,temp=0.05):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.mlp = MLPLayer(config.hidden_size)\n",
    "        self.sim = Similarity(temp)\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "    @add_start_docstrings_to_model_forward(BERT_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n",
    "    @add_code_sample_docstrings(\n",
    "        processor_class=_TOKENIZER_FOR_DOC,\n",
    "        checkpoint=_CHECKPOINT_FOR_DOC,\n",
    "        output_type=SequenceClassifierOutput,\n",
    "        config_class=_CONFIG_FOR_DOC,\n",
    "    )\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "        sent_emb=False, # if true, return sentence embedding for evaluation\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
    "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        if sent_emb:\n",
    "            # return sentence embedding for evaluation\n",
    "            \n",
    "            outputs = self.bert(\n",
    "                input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                token_type_ids=token_type_ids,\n",
    "                position_ids=position_ids,\n",
    "                head_mask=head_mask,\n",
    "                inputs_embeds=inputs_embeds,\n",
    "                output_attentions=output_attentions,\n",
    "                output_hidden_states=output_hidden_states,\n",
    "                return_dict=return_dict,\n",
    "            )\n",
    "\n",
    "            return outputs\n",
    "        \n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        \n",
    "        # view_0 & view_1 are the same sentence go through bert twice\n",
    "        outputs_view_0 = self.bert(\n",
    "            input_ids[:,0],\n",
    "            attention_mask=attention_mask[:,0],\n",
    "            token_type_ids=token_type_ids[:,0],\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        outputs_view_1 = self.bert(\n",
    "            input_ids[:,1],\n",
    "            attention_mask=attention_mask[:,1],\n",
    "            token_type_ids=token_type_ids[:,1],\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "        \n",
    "        # go through mlp twice\n",
    "        pooled_output_0 = self.mlp(outputs_view_0.last_hidden_state[:, 0])\n",
    "        pooled_output_1 = self.mlp(outputs_view_1.last_hidden_state[:, 0])\n",
    "\n",
    "        sim_matrix = self.sim(pooled_output_0.unsqueeze(1), pooled_output_1.unsqueeze(0))\n",
    "        \n",
    "        # labels = [0,1,...,batch_size-1]\n",
    "        labels = torch.arange(0,sim_matrix.shape[0],step=1).cuda()\n",
    "        \n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(sim_matrix,labels)\n",
    "        \n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=sim_matrix,\n",
    "            hidden_states=[pooled_output_0,pooled_output_1],\n",
    "            attentions=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4480a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# override the evaluate method\n",
    "class SimCSETrainer(Trainer):\n",
    "    def __init__(self,**paraments):\n",
    "        super().__init__(**paraments)\n",
    "        \n",
    "        self.best_sts = 0.0\n",
    "        \n",
    "    def evaluate(\n",
    "        self,\n",
    "        eval_dataset: Optional[Dataset] = None,\n",
    "        ignore_keys: Optional[List[str]] = None,\n",
    "        metric_key_prefix: str = \"eval\",\n",
    "        eval_senteval_transfer: bool = False,\n",
    "    ) -> Dict[str, float]:\n",
    "\n",
    "        # SentEval prepare and batcher\n",
    "        def prepare(params, samples):\n",
    "            return\n",
    "\n",
    "        def batcher(params, batch):\n",
    "            sentences = [' '.join(s) for s in batch]\n",
    "            batch = self.tokenizer.batch_encode_plus(\n",
    "                sentences,\n",
    "                return_tensors='pt',\n",
    "                padding=True,\n",
    "            )\n",
    "            for k in batch:\n",
    "                batch[k] = batch[k].to(self.args.device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch, output_hidden_states=True, return_dict=True, sent_emb=True)\n",
    "                pooler_output = outputs.last_hidden_state[:, 0]\n",
    "            return pooler_output.cpu()\n",
    "\n",
    "        # Set params for SentEval (fastmode)\n",
    "        params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 5}\n",
    "        params['classifier'] = {'nhid': 0, 'optim': 'rmsprop', 'batch_size': 128,\n",
    "                                            'tenacity': 3, 'epoch_size': 2}\n",
    "\n",
    "        se = senteval.engine.SE(params, batcher, prepare)\n",
    "        tasks = ['STSBenchmark', 'SICKRelatedness']\n",
    "        self.model.eval()\n",
    "        results = se.eval(tasks)\n",
    "        #print( results['STSBenchmark'] )\n",
    "        stsb_spearman = results['STSBenchmark']['spearman']\n",
    "        sickr_spearman = results['SICKRelatedness']['spearman']\n",
    "\n",
    "        metrics = {\"eval_stsb_spearman\": stsb_spearman, \"eval_sickr_spearman\": sickr_spearman, \"eval_avg_sts\": (stsb_spearman + sickr_spearman) / 2} \n",
    "        print(metrics)\n",
    "        \n",
    "        # save and eval model\n",
    "        if metrics[\"eval_avg_sts\"]>self.best_sts:\n",
    "            self.best_sts = metrics[\"eval_avg_sts\"]\n",
    "            evalModel(self.model.bert,tokenizer, pooler = 'cls_before_pooler')\n",
    "            self.save_model(self.args.output_dir+\"/best-model\")\n",
    "            \n",
    "        self.log(metrics)\n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20d20c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SimCSEModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['mlp.dense.bias', 'mlp.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = SimCSEModel(config).from_pretrained(\"bert-base-uncased\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a6c3010",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir = 'trainer_models',\n",
    "    evaluation_strategy   = \"steps\",\n",
    "    eval_steps            = 125,\n",
    "    learning_rate         = 3e-5,\n",
    "    num_train_epochs      = 1.0,\n",
    "    per_device_train_batch_size = 64,\n",
    "    per_device_eval_batch_size  = 64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c936bc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.3.1+cu121\n",
      "Is CUDA enabled? True\n"
     ]
    }
   ],
   "source": [
    "#import torch\n",
    "\n",
    "print(\"Torch version:\",torch.__version__)\n",
    "\n",
    "print(\"Is CUDA enabled?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "321061ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fooli\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SimCSETrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba24ad1c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.5037055626042174, 'eval_sickr_spearman': 0.6510762547103278, 'eval_avg_sts': 0.5773909086572726}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.5759484546752985, 'pearson': 0.5000071366357604, 'spearman': 0.5037055626042174, 'mse': 1.9113272058490889, 'yhat': array([2.53563102, 2.34177347, 3.50484297, ..., 2.26899934, 3.69027919,\n",
      "       4.39055101]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.7027961395366927, 'pearson': 0.7018062321019634, 'spearman': 0.6510762547103278, 'mse': 0.5183835427621566, 'yhat': array([3.28330554, 4.05144345, 2.8199942 , ..., 2.16892583, 3.15235038,\n",
      "       4.38313658]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 32.50 | 24.01 | 28.50 | 35.51 | 51.09 |    50.37     |      65.11      | 41.01 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_stsb_spearman': 0.5037055626042174,\n",
       " 'eval_sickr_spearman': 0.6510762547103278,\n",
       " 'eval_avg_sts': 0.5773909086572726}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the evaluate method and see what are the initial results\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d215e1b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15554' max='15554' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15554/15554 4:54:38, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.6356538542097421, 'eval_sickr_spearman': 0.7364087253319732, 'eval_avg_sts': 0.6860312897708576}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.669761079244177, 'pearson': 0.6393349237026601, 'spearman': 0.6356538542097421, 'mse': 1.528943769716942, 'yhat': array([2.50391819, 1.94326281, 3.01332702, ..., 3.71976026, 4.12019033,\n",
      "       4.64292709]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.7920563030868204, 'pearson': 0.8155281336789253, 'spearman': 0.7364087253319732, 'mse': 0.3426460284378517, 'yhat': array([2.49770307, 3.80050344, 1.20151165, ..., 1.11200512, 3.06076166,\n",
      "       4.33041312]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 50.95 | 59.13 | 56.48 | 66.53 | 69.14 |    63.57     |      73.64      | 62.78 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.6560745356937246, 'eval_sickr_spearman': 0.7520651828203182, 'eval_avg_sts': 0.7040698592570214}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.6958029944524743, 'pearson': 0.6590478648816965, 'spearman': 0.6560745356937246, 'mse': 1.432812383866675, 'yhat': array([2.58661089, 1.54228978, 3.73615917, ..., 3.73098614, 3.9025515 ,\n",
      "       4.48635508]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.8036337911803945, 'pearson': 0.8262345776806426, 'spearman': 0.7520651828203182, 'mse': 0.3277476426271373, 'yhat': array([2.847613  , 4.06123937, 1.14378521, ..., 1.37955946, 3.06938944,\n",
      "       4.3455292 ]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 54.93 | 63.48 | 60.21 | 70.99 | 71.25 |    65.61     |      75.21      | 65.95 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.6709547140862625, 'eval_sickr_spearman': 0.7546761332654953, 'eval_avg_sts': 0.7128154236758789}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.7198034214693403, 'pearson': 0.6726607162906552, 'spearman': 0.6709547140862625, 'mse': 1.3842678666884296, 'yhat': array([2.23126443, 1.73863343, 3.72184924, ..., 3.71438924, 3.95351542,\n",
      "       4.72325702]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.8121442006759007, 'pearson': 0.83142181087557, 'spearman': 0.7546761332654953, 'mse': 0.3175656878935538, 'yhat': array([3.00529802, 4.13868752, 1.09830666, ..., 1.40390158, 3.05646906,\n",
      "       4.37881975]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 56.46 | 64.93 | 61.71 | 72.14 | 72.78 |    67.10     |      75.47      | 67.23 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.6679269655062073, 'eval_sickr_spearman': 0.750617580167149, 'eval_avg_sts': 0.7092722728366782}\n",
      "{'eval_stsb_spearman': 0.6815294034306547, 'eval_sickr_spearman': 0.7545499233759335, 'eval_avg_sts': 0.7180396634032942}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.7238805158596986, 'pearson': 0.6849846894648706, 'spearman': 0.6815294034306547, 'mse': 1.3356243968920536, 'yhat': array([1.90783977, 1.79384899, 3.63944809, ..., 3.51174457, 3.77261576,\n",
      "       4.89633473]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.817704595790797, 'pearson': 0.831245404583853, 'spearman': 0.7545499233759335, 'mse': 0.3172524003007244, 'yhat': array([2.85526057, 4.22747046, 1.13975845, ..., 1.22879049, 2.9842772 ,\n",
      "       4.60928524]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 57.64 | 65.04 | 61.47 | 72.18 | 72.99 |    68.15     |      75.45      | 67.56 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.6830968667181933, 'eval_sickr_spearman': 0.748826308924811, 'eval_avg_sts': 0.7159615878215021}\n",
      "{'eval_stsb_spearman': 0.6895729277834921, 'eval_sickr_spearman': 0.7508946095973346, 'eval_avg_sts': 0.7202337686904133}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.7269378339689967, 'pearson': 0.690263515258811, 'spearman': 0.6895729277834921, 'mse': 1.3069826666678859, 'yhat': array([2.05923765, 1.70912146, 3.37987664, ..., 3.31801381, 3.60768814,\n",
      "       4.5779184 ]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.8236851072826836, 'pearson': 0.8320477966428832, 'spearman': 0.7508946095973346, 'mse': 0.31430988308315677, 'yhat': array([3.14771066, 4.19024933, 1.17269916, ..., 1.24272453, 3.07756659,\n",
      "       4.56510253]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 59.57 | 66.95 | 62.91 | 73.09 | 74.04 |    68.96     |      75.09      | 68.66 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.6932274527653125, 'eval_sickr_spearman': 0.7550432130059219, 'eval_avg_sts': 0.7241353328856173}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.7347344533701589, 'pearson': 0.6960158955865321, 'spearman': 0.6932274527653125, 'mse': 1.3004792667803118, 'yhat': array([2.09668017, 1.46415867, 3.47410203, ..., 3.32871085, 3.61155178,\n",
      "       4.57309818]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.8272965649860782, 'pearson': 0.8340114333606321, 'spearman': 0.7550432130059219, 'mse': 0.31140097734251554, 'yhat': array([3.32003725, 4.26907938, 1.2476683 , ..., 1.28996926, 3.15946561,\n",
      "       4.53703192]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 60.17 | 68.33 | 64.24 | 74.12 | 74.60 |    69.32     |      75.50      | 69.47 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.7222083798702562, 'eval_sickr_spearman': 0.7550850666388403, 'eval_avg_sts': 0.7386467232545483}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.7479621501583249, 'pearson': 0.7215112162447336, 'spearman': 0.7222083798702562, 'mse': 1.2177745530274553, 'yhat': array([2.05226633, 1.07237008, 2.94880414, ..., 3.73496773, 3.79829079,\n",
      "       4.39685859]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.8227457825769263, 'pearson': 0.8385676857807096, 'spearman': 0.7550850666388403, 'mse': 0.3058703081085805, 'yhat': array([3.66283988, 4.00380548, 1.13586572, ..., 1.20704678, 3.12050738,\n",
      "       4.63854379]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 62.83 | 72.19 | 68.47 | 75.71 | 76.68 |    72.22     |      75.51      | 71.94 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.7299057908611254, 'eval_sickr_spearman': 0.7572029837376377, 'eval_avg_sts': 0.7435543872993815}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.7505733069445852, 'pearson': 0.7281157466032641, 'spearman': 0.7299057908611254, 'mse': 1.1987382949996237, 'yhat': array([1.89944637, 1.05941842, 2.96629933, ..., 3.61023334, 3.59014544,\n",
      "       4.04320696]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.8249268553282693, 'pearson': 0.8389828459142483, 'spearman': 0.7572029837376377, 'mse': 0.305318354797034, 'yhat': array([3.56349474, 4.03256352, 1.10957249, ..., 1.29471726, 3.06725819,\n",
      "       4.75267424]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 62.85 | 72.54 | 68.79 | 76.29 | 77.10 |    72.99     |      75.72      | 72.33 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.7354697623324749, 'eval_sickr_spearman': 0.7575626666894235, 'eval_avg_sts': 0.7465162145109492}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.7550888259840749, 'pearson': 0.7339691637233476, 'spearman': 0.7354697623324749, 'mse': 1.1801964400724876, 'yhat': array([1.82982203, 1.08886909, 2.9281048 , ..., 3.64386001, 3.54454044,\n",
      "       4.09038667]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.8269056928342424, 'pearson': 0.8390872759471761, 'spearman': 0.7575626666894235, 'mse': 0.30529100843112406, 'yhat': array([3.52687298, 4.02859228, 1.10929971, ..., 1.33025472, 3.06276146,\n",
      "       4.76168505]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 63.19 | 72.70 | 69.01 | 76.54 | 77.23 |    73.55     |      75.76      | 72.57 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.7408794243381788, 'eval_sickr_spearman': 0.7595421574623632, 'eval_avg_sts': 0.750210790900271}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.7560494836429055, 'pearson': 0.7406730585032157, 'spearman': 0.7408794243381788, 'mse': 1.1610469293746721, 'yhat': array([1.90438708, 1.09904643, 2.75830482, ..., 3.74014381, 3.59221664,\n",
      "       3.95171628]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.8257496909530981, 'pearson': 0.8397674396235115, 'spearman': 0.7595421574623632, 'mse': 0.30339949097238156, 'yhat': array([3.46508199, 4.02553601, 1.10223191, ..., 1.31972624, 3.05993573,\n",
      "       4.75742151]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 63.51 | 72.73 | 69.13 | 76.87 | 77.50 |    74.09     |      75.95      | 72.83 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.7526480414533494, 'eval_sickr_spearman': 0.7665785644195767, 'eval_avg_sts': 0.7596133029364631}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.7798566440940793, 'pearson': 0.7535703471604697, 'spearman': 0.7526480414533494, 'mse': 1.1203913110454276, 'yhat': array([1.43384198, 1.06934633, 2.7522268 , ..., 3.14906282, 3.51677624,\n",
      "       4.01520283]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.8389708828510081, 'pearson': 0.844080502823924, 'spearman': 0.7665785644195767, 'mse': 0.29672846426518185, 'yhat': array([3.3611607 , 3.99408721, 1.04631945, ..., 1.37263827, 3.05123463,\n",
      "       4.61751782]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 66.57 | 74.84 | 73.43 | 80.00 | 78.57 |    75.26     |      76.66      | 75.05 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.7251176618094949, 'eval_sickr_spearman': 0.7566322160995063, 'eval_avg_sts': 0.7408749389545006}\n",
      "{'eval_stsb_spearman': 0.730990685157358, 'eval_sickr_spearman': 0.7557127107169485, 'eval_avg_sts': 0.7433516979371533}\n",
      "{'eval_stsb_spearman': 0.7342572041728469, 'eval_sickr_spearman': 0.756894931292101, 'eval_avg_sts': 0.7455760677324739}\n",
      "{'eval_stsb_spearman': 0.737051554045226, 'eval_sickr_spearman': 0.7578466571357688, 'eval_avg_sts': 0.7474491055904975}\n",
      "{'eval_stsb_spearman': 0.73918642984334, 'eval_sickr_spearman': 0.7596515363550919, 'eval_avg_sts': 0.749418983099216}\n",
      "{'eval_stsb_spearman': 0.7385371150921471, 'eval_sickr_spearman': 0.7575992632458489, 'eval_avg_sts': 0.748068189168998}\n",
      "{'eval_stsb_spearman': 0.7320227280664587, 'eval_sickr_spearman': 0.7607742896968848, 'eval_avg_sts': 0.7463985088816718}\n",
      "{'eval_stsb_spearman': 0.7399764678267752, 'eval_sickr_spearman': 0.7603798064827936, 'eval_avg_sts': 0.7501781371547844}\n",
      "{'eval_stsb_spearman': 0.7401552604592754, 'eval_sickr_spearman': 0.7618657186667295, 'eval_avg_sts': 0.7510104895630024}\n",
      "{'eval_stsb_spearman': 0.7420198180886173, 'eval_sickr_spearman': 0.763402487787981, 'eval_avg_sts': 0.7527111529382992}\n",
      "{'eval_stsb_spearman': 0.7317456545777903, 'eval_sickr_spearman': 0.7705737282820422, 'eval_avg_sts': 0.7511596914299162}\n",
      "{'eval_stsb_spearman': 0.7460493606801016, 'eval_sickr_spearman': 0.7618867858719965, 'eval_avg_sts': 0.7539680732760491}\n",
      "{'eval_stsb_spearman': 0.7485194437438707, 'eval_sickr_spearman': 0.7637515032984648, 'eval_avg_sts': 0.7561354735211677}\n",
      "{'eval_stsb_spearman': 0.764007678811421, 'eval_sickr_spearman': 0.7679873939125843, 'eval_avg_sts': 0.7659975363620026}\n",
      "MSRpar\n",
      "MSRvid\n",
      "SMTeuroparl\n",
      "surprise.OnWN\n",
      "surprise.SMTnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:57: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
      "C:\\JupyterDoc\\SimCSE-reproduce-main/SentEval-main\\senteval\\sts.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FNWN\n",
      "headlines\n",
      "OnWN\n",
      "deft-forum\n",
      "deft-news\n",
      "headlines\n",
      "images\n",
      "OnWN\n",
      "tweet-news\n",
      "answers-forums\n",
      "answers-students\n",
      "belief\n",
      "headlines\n",
      "images\n",
      "answer-answer\n",
      "headlines\n",
      "plagiarism\n",
      "postediting\n",
      "question-question\n",
      "task STSBenchmark results[task] {'devpearson': 0.7819614668647625, 'pearson': 0.7649576556583645, 'spearman': 0.764007678811421, 'mse': 1.0602618562574242, 'yhat': array([1.57205723, 1.52914385, 2.60752142, ..., 4.32040943, 3.3866449 ,\n",
      "       3.82319125]), 'ndev': 1500, 'ntest': 1379}\n",
      "task SICKRelatedness results[task] {'devpearson': 0.8409532982032971, 'pearson': 0.8463136847315818, 'spearman': 0.7679873939125843, 'mse': 0.29155313952833717, 'yhat': array([3.65635441, 3.99775095, 1.10133373, ..., 1.29884879, 3.09823689,\n",
      "       4.54710375]), 'ndev': 500, 'ntest': 4927}\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "| 67.62 | 73.84 | 74.25 | 80.18 | 78.53 |    76.40     |      76.80      | 75.37 |\n",
      "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
      "{'eval_stsb_spearman': 0.7641259553228542, 'eval_sickr_spearman': 0.767215594119404, 'eval_avg_sts': 0.7656707747211291}\n",
      "{'eval_stsb_spearman': 0.7542489514773437, 'eval_sickr_spearman': 0.7673659878758817, 'eval_avg_sts': 0.7608074696766127}\n",
      "{'eval_stsb_spearman': 0.7430370309058191, 'eval_sickr_spearman': 0.7579510052204153, 'eval_avg_sts': 0.7504940180631172}\n",
      "{'eval_stsb_spearman': 0.7461690139115273, 'eval_sickr_spearman': 0.7629851180360823, 'eval_avg_sts': 0.7545770659738048}\n",
      "{'eval_stsb_spearman': 0.7433807733772845, 'eval_sickr_spearman': 0.7669466015845684, 'eval_avg_sts': 0.7551636874809264}\n",
      "{'eval_stsb_spearman': 0.7478271414263239, 'eval_sickr_spearman': 0.7681880459085948, 'eval_avg_sts': 0.7580075936674593}\n",
      "{'eval_stsb_spearman': 0.7327361164198303, 'eval_sickr_spearman': 0.7698743083805956, 'eval_avg_sts': 0.7513052124002129}\n",
      "{'eval_stsb_spearman': 0.7327266992885673, 'eval_sickr_spearman': 0.768329766578039, 'eval_avg_sts': 0.7505282329333032}\n",
      "{'eval_stsb_spearman': 0.7344574745535158, 'eval_sickr_spearman': 0.7689662151475063, 'eval_avg_sts': 0.7517118448505111}\n",
      "{'eval_stsb_spearman': 0.734487086632289, 'eval_sickr_spearman': 0.7693011694916786, 'eval_avg_sts': 0.7518941280619837}\n",
      "{'eval_stsb_spearman': 0.7489805189519992, 'eval_sickr_spearman': 0.7701225814447584, 'eval_avg_sts': 0.7595515501983788}\n",
      "{'eval_stsb_spearman': 0.7459384717260322, 'eval_sickr_spearman': 0.7672585828086328, 'eval_avg_sts': 0.7565985272673326}\n",
      "{'eval_stsb_spearman': 0.7451196188328044, 'eval_sickr_spearman': 0.7680355700109252, 'eval_avg_sts': 0.7565775944218648}\n",
      "{'eval_stsb_spearman': 0.7456156961731876, 'eval_sickr_spearman': 0.7679352589201333, 'eval_avg_sts': 0.7567754775466604}\n",
      "{'eval_stsb_spearman': 0.7437695879661741, 'eval_sickr_spearman': 0.7652850996928913, 'eval_avg_sts': 0.7545273438295327}\n",
      "{'eval_stsb_spearman': 0.7379607802448482, 'eval_sickr_spearman': 0.7666380552936688, 'eval_avg_sts': 0.7522994177692586}\n",
      "{'eval_stsb_spearman': 0.7347270138790307, 'eval_sickr_spearman': 0.7680798479482472, 'eval_avg_sts': 0.751403430913639}\n",
      "{'eval_stsb_spearman': 0.7346600837546712, 'eval_sickr_spearman': 0.7679713810557466, 'eval_avg_sts': 0.7513157324052089}\n",
      "{'eval_stsb_spearman': 0.7353152054695593, 'eval_sickr_spearman': 0.766883587337884, 'eval_avg_sts': 0.7510993964037216}\n",
      "{'eval_stsb_spearman': 0.7350162441946545, 'eval_sickr_spearman': 0.7676243336989748, 'eval_avg_sts': 0.7513202889468147}\n",
      "{'eval_stsb_spearman': 0.7398969914538319, 'eval_sickr_spearman': 0.7713465587810387, 'eval_avg_sts': 0.7556217751174353}\n",
      "{'eval_stsb_spearman': 0.74049465744351, 'eval_sickr_spearman': 0.7718366383408795, 'eval_avg_sts': 0.7561656478921948}\n",
      "{'eval_stsb_spearman': 0.7426968001011564, 'eval_sickr_spearman': 0.7740063928901711, 'eval_avg_sts': 0.7583515964956637}\n",
      "{'eval_stsb_spearman': 0.7383814701393874, 'eval_sickr_spearman': 0.7710973464620454, 'eval_avg_sts': 0.7547394083007164}\n",
      "{'eval_stsb_spearman': 0.7364212980466744, 'eval_sickr_spearman': 0.761253877941389, 'eval_avg_sts': 0.7488375879940317}\n",
      "{'eval_stsb_spearman': 0.7316708764622589, 'eval_sickr_spearman': 0.7642083502124625, 'eval_avg_sts': 0.7479396133373607}\n",
      "{'eval_stsb_spearman': 0.7328178514382189, 'eval_sickr_spearman': 0.7658228261700929, 'eval_avg_sts': 0.7493203388041558}\n",
      "{'eval_stsb_spearman': 0.7351815147337842, 'eval_sickr_spearman': 0.7661727318971996, 'eval_avg_sts': 0.7506771233154919}\n",
      "{'eval_stsb_spearman': 0.7342463278558348, 'eval_sickr_spearman': 0.766656189592534, 'eval_avg_sts': 0.7504512587241844}\n",
      "{'eval_stsb_spearman': 0.7340056950687308, 'eval_sickr_spearman': 0.7705800813649732, 'eval_avg_sts': 0.752292888216852}\n",
      "{'eval_stsb_spearman': 0.7302257671596757, 'eval_sickr_spearman': 0.7657529753849903, 'eval_avg_sts': 0.747989371272333}\n",
      "{'eval_stsb_spearman': 0.7282211483148598, 'eval_sickr_spearman': 0.7619475291527859, 'eval_avg_sts': 0.7450843387338228}\n",
      "{'eval_stsb_spearman': 0.7295146511960422, 'eval_sickr_spearman': 0.7629152599730472, 'eval_avg_sts': 0.7462149555845448}\n",
      "{'eval_stsb_spearman': 0.7322471128087928, 'eval_sickr_spearman': 0.7640111023815298, 'eval_avg_sts': 0.7481291075951613}\n",
      "{'eval_stsb_spearman': 0.7301702447983153, 'eval_sickr_spearman': 0.7645649308075011, 'eval_avg_sts': 0.7473675878029082}\n",
      "{'eval_stsb_spearman': 0.7314784769799162, 'eval_sickr_spearman': 0.7654282363468391, 'eval_avg_sts': 0.7484533566633776}\n",
      "{'eval_stsb_spearman': 0.7457287269462136, 'eval_sickr_spearman': 0.7651898798421175, 'eval_avg_sts': 0.7554593033941656}\n",
      "{'eval_stsb_spearman': 0.7445053268303055, 'eval_sickr_spearman': 0.7644087750365943, 'eval_avg_sts': 0.7544570509334498}\n",
      "{'eval_stsb_spearman': 0.7454353710520435, 'eval_sickr_spearman': 0.7656630299773624, 'eval_avg_sts': 0.7555492005147029}\n",
      "{'eval_stsb_spearman': 0.7452873541817711, 'eval_sickr_spearman': 0.76734059311158, 'eval_avg_sts': 0.7563139736466755}\n",
      "{'eval_stsb_spearman': 0.7412854765609176, 'eval_sickr_spearman': 0.7642353222804056, 'eval_avg_sts': 0.7527603994206615}\n",
      "{'eval_stsb_spearman': 0.7353097146245977, 'eval_sickr_spearman': 0.7606673805328968, 'eval_avg_sts': 0.7479885475787473}\n",
      "{'eval_stsb_spearman': 0.7364982385976018, 'eval_sickr_spearman': 0.7614533339974198, 'eval_avg_sts': 0.7489757862975108}\n",
      "{'eval_stsb_spearman': 0.7370022944999379, 'eval_sickr_spearman': 0.7593933250984606, 'eval_avg_sts': 0.7481978097991993}\n",
      "{'eval_stsb_spearman': 0.7383082038960608, 'eval_sickr_spearman': 0.7607531249171299, 'eval_avg_sts': 0.7495306644065953}\n",
      "{'eval_stsb_spearman': 0.7390254956285791, 'eval_sickr_spearman': 0.7612731975393948, 'eval_avg_sts': 0.750149346583987}\n",
      "{'eval_stsb_spearman': 0.7394311401039657, 'eval_sickr_spearman': 0.7616567844337556, 'eval_avg_sts': 0.7505439622688607}\n",
      "{'eval_stsb_spearman': 0.7401929908336449, 'eval_sickr_spearman': 0.7625178383815567, 'eval_avg_sts': 0.7513554146076008}\n",
      "{'eval_stsb_spearman': 0.7343096753012122, 'eval_sickr_spearman': 0.7580222878508951, 'eval_avg_sts': 0.7461659815760536}\n",
      "{'eval_stsb_spearman': 0.7343231332545497, 'eval_sickr_spearman': 0.7606899512084352, 'eval_avg_sts': 0.7475065422314924}\n",
      "{'eval_stsb_spearman': 0.7374450920893977, 'eval_sickr_spearman': 0.7625348996622119, 'eval_avg_sts': 0.7499899958758047}\n",
      "{'eval_stsb_spearman': 0.7390339185893317, 'eval_sickr_spearman': 0.7628498157501912, 'eval_avg_sts': 0.7509418671697614}\n",
      "{'eval_stsb_spearman': 0.7396630887887545, 'eval_sickr_spearman': 0.7644432821738951, 'eval_avg_sts': 0.7520531854813248}\n",
      "{'eval_stsb_spearman': 0.7409001415688142, 'eval_sickr_spearman': 0.7653382785918225, 'eval_avg_sts': 0.7531192100803183}\n",
      "{'eval_stsb_spearman': 0.7413635097831199, 'eval_sickr_spearman': 0.7686978755686952, 'eval_avg_sts': 0.7550306926759076}\n",
      "{'eval_stsb_spearman': 0.7299624883595176, 'eval_sickr_spearman': 0.7666704891738745, 'eval_avg_sts': 0.748316488766696}\n",
      "{'eval_stsb_spearman': 0.7373764599634501, 'eval_sickr_spearman': 0.7673878455148082, 'eval_avg_sts': 0.7523821527391292}\n",
      "{'eval_stsb_spearman': 0.7378886960107, 'eval_sickr_spearman': 0.7673058363662915, 'eval_avg_sts': 0.7525972661884957}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_stsb_spearman': 0.7383297068420996, 'eval_sickr_spearman': 0.7638135739235594, 'eval_avg_sts': 0.7510716403828295}\n",
      "{'eval_stsb_spearman': 0.7380046978416798, 'eval_sickr_spearman': 0.7634448827986906, 'eval_avg_sts': 0.7507247903201852}\n",
      "{'eval_stsb_spearman': 0.7383778897511207, 'eval_sickr_spearman': 0.7639313091375848, 'eval_avg_sts': 0.7511545994443527}\n",
      "{'eval_stsb_spearman': 0.7396529844428529, 'eval_sickr_spearman': 0.7635169744341057, 'eval_avg_sts': 0.7515849794384792}\n",
      "{'eval_stsb_spearman': 0.7400251913446453, 'eval_sickr_spearman': 0.7638469881663659, 'eval_avg_sts': 0.7519360897555056}\n",
      "{'eval_stsb_spearman': 0.7403129120787797, 'eval_sickr_spearman': 0.7633072736591682, 'eval_avg_sts': 0.7518100928689739}\n",
      "{'eval_stsb_spearman': 0.743170904898831, 'eval_sickr_spearman': 0.7681249301723967, 'eval_avg_sts': 0.7556479175356139}\n",
      "{'eval_stsb_spearman': 0.7419033168816669, 'eval_sickr_spearman': 0.7676830564249384, 'eval_avg_sts': 0.7547931866533026}\n",
      "{'eval_stsb_spearman': 0.7399374111281534, 'eval_sickr_spearman': 0.7684457329533173, 'eval_avg_sts': 0.7541915720407353}\n",
      "{'eval_stsb_spearman': 0.7454404152074902, 'eval_sickr_spearman': 0.7709268837816728, 'eval_avg_sts': 0.7581836494945815}\n",
      "{'eval_stsb_spearman': 0.7332299007540364, 'eval_sickr_spearman': 0.769561241991703, 'eval_avg_sts': 0.7513955713728697}\n",
      "{'eval_stsb_spearman': 0.735993758912905, 'eval_sickr_spearman': 0.7696549051680094, 'eval_avg_sts': 0.7528243320404572}\n",
      "{'eval_stsb_spearman': 0.7390826718865028, 'eval_sickr_spearman': 0.7679794332096584, 'eval_avg_sts': 0.7535310525480806}\n",
      "{'eval_stsb_spearman': 0.7330130226862701, 'eval_sickr_spearman': 0.7672315222008766, 'eval_avg_sts': 0.7501222724435734}\n",
      "{'eval_stsb_spearman': 0.7338425915464277, 'eval_sickr_spearman': 0.7668154974610917, 'eval_avg_sts': 0.7503290445037597}\n",
      "{'eval_stsb_spearman': 0.7361474109432133, 'eval_sickr_spearman': 0.7670790764689823, 'eval_avg_sts': 0.7516132437060978}\n",
      "{'eval_stsb_spearman': 0.7364769853395482, 'eval_sickr_spearman': 0.7679472203778294, 'eval_avg_sts': 0.7522121028586888}\n",
      "{'eval_stsb_spearman': 0.734689659181997, 'eval_sickr_spearman': 0.7674199385870036, 'eval_avg_sts': 0.7510547988845003}\n",
      "{'eval_stsb_spearman': 0.7344853388163918, 'eval_sickr_spearman': 0.7689968633744311, 'eval_avg_sts': 0.7517411010954114}\n",
      "{'eval_stsb_spearman': 0.7347531807217496, 'eval_sickr_spearman': 0.7690154456425883, 'eval_avg_sts': 0.7518843131821689}\n",
      "{'eval_stsb_spearman': 0.7336158519485989, 'eval_sickr_spearman': 0.7675363402328365, 'eval_avg_sts': 0.7505760960907177}\n",
      "{'eval_stsb_spearman': 0.7350640903685027, 'eval_sickr_spearman': 0.7684612407718339, 'eval_avg_sts': 0.7517626655701684}\n",
      "{'eval_stsb_spearman': 0.7338602827419383, 'eval_sickr_spearman': 0.7687396549667025, 'eval_avg_sts': 0.7512999688543204}\n",
      "{'eval_stsb_spearman': 0.7358703305823985, 'eval_sickr_spearman': 0.7685029527611287, 'eval_avg_sts': 0.7521866416717635}\n",
      "{'eval_stsb_spearman': 0.7368775398451789, 'eval_sickr_spearman': 0.7684445984993187, 'eval_avg_sts': 0.7526610691722488}\n",
      "{'eval_stsb_spearman': 0.7374406114499547, 'eval_sickr_spearman': 0.7685146173293724, 'eval_avg_sts': 0.7529776143896636}\n",
      "{'eval_stsb_spearman': 0.7339639009651323, 'eval_sickr_spearman': 0.7651776246069127, 'eval_avg_sts': 0.7495707627860225}\n",
      "{'eval_stsb_spearman': 0.7343464137957868, 'eval_sickr_spearman': 0.7654022453943863, 'eval_avg_sts': 0.7498743295950865}\n",
      "{'eval_stsb_spearman': 0.7348759355819107, 'eval_sickr_spearman': 0.7649598410605541, 'eval_avg_sts': 0.7499178883212324}\n",
      "{'eval_stsb_spearman': 0.7347306446630376, 'eval_sickr_spearman': 0.7665414715583494, 'eval_avg_sts': 0.7506360581106934}\n",
      "{'eval_stsb_spearman': 0.7343725508592047, 'eval_sickr_spearman': 0.7666450787996625, 'eval_avg_sts': 0.7505088148294337}\n",
      "{'eval_stsb_spearman': 0.7347471469772235, 'eval_sickr_spearman': 0.7667626500845329, 'eval_avg_sts': 0.7507548985308783}\n",
      "{'eval_stsb_spearman': 0.7347689179369714, 'eval_sickr_spearman': 0.7666092818119568, 'eval_avg_sts': 0.7506890998744641}\n",
      "{'eval_stsb_spearman': 0.7349169691679758, 'eval_sickr_spearman': 0.7666154947068505, 'eval_avg_sts': 0.7507662319374131}\n",
      "{'eval_stsb_spearman': 0.7373324576101464, 'eval_sickr_spearman': 0.7668929792838753, 'eval_avg_sts': 0.7521127184470109}\n",
      "{'eval_stsb_spearman': 0.7373649307925314, 'eval_sickr_spearman': 0.7668948851485236, 'eval_avg_sts': 0.7521299079705275}\n",
      "{'eval_stsb_spearman': 0.7371527395285998, 'eval_sickr_spearman': 0.7670758617309192, 'eval_avg_sts': 0.7521143006297595}\n",
      "{'eval_stsb_spearman': 0.7372465076753085, 'eval_sickr_spearman': 0.7670879467628896, 'eval_avg_sts': 0.7521672272190991}\n",
      "{'eval_stsb_spearman': 0.7373809864172023, 'eval_sickr_spearman': 0.7671009133783493, 'eval_avg_sts': 0.7522409498977758}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15554, training_loss=0.0002497303786418587, metrics={'train_runtime': 17679.5594, 'train_samples_per_second': 56.305, 'train_steps_per_second': 0.88, 'total_flos': 3.296430570287923e+16, 'train_loss': 0.0002497303786418587, 'epoch': 1.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4191c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
