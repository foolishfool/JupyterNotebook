{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988080f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fooli\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset,load_dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cded7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e150756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                        0\n",
      "0                                 YMCA in South Australia\n",
      "1       South Australia (SA)  has a unique position in...\n",
      "2       The compound of philosophical radicalism, evan...\n",
      "3       It was into this social setting that in Februa...\n",
      "4       for apprentices and others, after their day's ...\n",
      "...                                                   ...\n",
      "995442                                  Rubaschow: Roman.\n",
      "995443                 Typoskript, März 1940, 326 pages.\"\n",
      "995444  He deemed the discovery important because \"\"Da...\n",
      "995445  In 2018, he reported that Elsinor Verlag (publ...\n",
      "995446  He also reported a new English translation to ...\n",
      "\n",
      "[995447 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 995447\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use pandas to read simCSE-wiki.txt\n",
    "wiki_text_file = 'wiki1m_for_simcse.txt'\n",
    "wiki = pd.read_csv(wiki_text_file,sep = '\\t',header = None)\n",
    "print(wiki)\n",
    "wiki.columns = ['text']\n",
    "# use Dataset.from_pandas to convert panda dataframe to hugging face dataset\n",
    "wiki_dataset = Dataset.from_pandas(wiki,split= \"train\")\n",
    "wiki_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8097da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(examples):\n",
    "    \n",
    "    total = len(examples['text'])\n",
    "    # total = batch_size\n",
    "    \n",
    "    # Avoid \"None\" fields \n",
    "    for idx in range(total):\n",
    "        if examples['text'][idx] is None:\n",
    "            examples['text'][idx] = \" \"\n",
    "        if examples['text'][idx] is None:\n",
    "            examples['text'][idx] = \" \"\n",
    "\n",
    "    sentences = examples['text'] + examples['text']\n",
    "\n",
    "    # set max_length here:\n",
    "    sent_features = tokenizer(sentences, max_length=32, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    features = {}\n",
    "    for key in sent_features:\n",
    "        features[key] = [[sent_features[key][i], sent_features[key][i+total]] for i in range(total)]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf78d533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████| 995447/995447 [13:26<00:00, 1234.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = wiki_dataset.map(prepare_features,batched=True, remove_columns=['text'], batch_size=4000) \n",
    "#apply the prepare_features function to the entire dataset:\n",
    "#take about 15 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "425c31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49cc382b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 995447\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e17532e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|█████████████████████████████| 995447/995447 [00:00<00:00, 2141661.34 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset.save_to_disk(\"wiki_for_sts_32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b73fed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (GPU)",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
