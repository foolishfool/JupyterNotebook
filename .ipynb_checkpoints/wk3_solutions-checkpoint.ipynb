{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03106851",
   "metadata": {},
   "source": [
    "# Week 3 Workshop Solutions\n",
    "<auther>&copy; Prepared by Professor Yuefeng Li </author>\n",
    "\n",
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e831c5",
   "metadata": {},
   "source": [
    "Task 1: Write a program that loads (read) an XML document, and prints out the itemid and the number of words in \"\\<text\\>\" of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4083bce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J.J. Lehto of Finland and Steve Soper of Britain drove their ailing McLaren to victory in the fifth round of the world GT championship on Sunday, beating the Mercedes of German Bernd Schneider and Austrian Alexander Wurz by 15 seconds.\n",
      "Their victory enabled them to open up a 16-point lead in the overall standings over Schneider, who mounted a strong challenge on the struggling leaders in the final minutes of the four-hour race.\n",
      "But Soper, struggling with the car's handling caused by a broken undertray, just managed to hold on for the win.\n",
      "Lehto had opened up a lead of over 90 seconds during a mid-race downpour in the Ardennes mountains.\n",
      "&quot;I thought that everyone else was driving on dry-weather tyres,&quot; he joked afterwards.\n",
      "&quot;We swapped to rain tyres at exactly the right time and I was able to push hard and open up a big lead.&quot;\n",
      "Third to finish was the Porsche of France's Bob Wollek and Yannick Dalmas and Belgian Thierry Boutsen.\n",
      "The Belgian, a former Formula One driver, switched from the car he normally shares with German Hans Stuck following a power-steering failure on his own car.\n",
      "Document itemid: 741299 contains: 199 words\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "myfile=open('741299newsML.xml', 'r')\n",
    "start_end = False\n",
    "file_=myfile.readlines()\n",
    "word_count = 0 #wk3\n",
    "for line in file_:\n",
    "    line = line.strip()\n",
    "    if(start_end == False):\n",
    "        if line.startswith(\"<newsitem \"):\n",
    "            for part in line.split():\n",
    "                if part.startswith(\"itemid=\"):\n",
    "                    docid = part.split(\"=\")[1].split(\"\\\"\")[1]\n",
    "                    break  \n",
    "        if line.startswith(\"<text>\"):\n",
    "            start_end = True  \n",
    "    elif line.startswith(\"</text>\"):\n",
    "        break\n",
    "    else:\n",
    "        line = line.replace(\"<p>\", \"\").replace(\"</p>\", \"\")\n",
    "        print(line)\n",
    "        line = line.translate(str.maketrans('','', string.digits)).translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "        for term in line.split():\n",
    "            word_count += 1 #wk3\n",
    "        #print(line)\n",
    "myfile.close()\n",
    "print('Document itemid: '+ docid+ ' contains: '+ str(word_count) + ' words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c8aea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This program firstly opens the .XML file and then represents it in a list of lines (strings)\n",
    "# file_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d2d2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each line, it firstly gets the 'itemid' by using recognizes tag <newsitem>, and saves it in 'docid'\n",
    "# It uses boolean variable 'start_end' to control the processing for <text> part. \n",
    "## for each line in <text>, it removes <p> and </p> by using .replace method; and then uses .maketrans and .translate \n",
    "## methods to remove digits and punctuations.\n",
    "## It also counts terms (works) in the line by using word_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce989ff1",
   "metadata": {},
   "source": [
    "## Execises for using  .maketrans and .translate methods\n",
    "\n",
    "You may need to review week 2 lecture notes about the String Methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec68217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lehto had opened up a lead of over  seconds during a mid race downpour in the Ardennes mountains \n",
      "Lehto had opened up a lead of over 90 seconds during a mid-race downpour in the Ardennes mountains.\n",
      "{48: None, 49: None, 50: None, 51: None, 52: None, 53: None, 54: None, 55: None, 56: None, 57: None}\n",
      "Lehto had opened up a lead of over  seconds during a mid-race downpour in the Ardennes mountains.\n",
      "{33: 32, 34: 32, 35: 32, 36: 32, 37: 32, 38: 32, 39: 32, 40: 32, 41: 32, 42: 32, 43: 32, 44: 32, 45: 32, 46: 32, 47: 32, 58: 32, 59: 32, 60: 32, 61: 32, 62: 32, 63: 32, 64: 32, 91: 32, 92: 32, 93: 32, 94: 32, 95: 32, 96: 32, 123: 32, 124: 32, 125: 32, 126: 32}\n",
      "Lehto had opened up a lead of over  seconds during a mid race downpour in the Ardennes mountains \n"
     ]
    }
   ],
   "source": [
    "line_s1 = \"Lehto had opened up a lead of over 90 seconds during a mid-race downpour in the Ardennes mountains.\"\n",
    "line_s2 = line_s1.translate(str.maketrans('','', string.digits)).translate(str.maketrans(string.punctuation, \\\n",
    "                                                                            ' '*len(string.punctuation)))\n",
    "print(line_s2)\n",
    "print(line_s1)\n",
    "\n",
    "mapping_tbl_digits=line_s1.maketrans('','', string.digits) # Remove digits\n",
    "line_s3 = line_s1.translate(mapping_tbl_digits)\n",
    "print(mapping_tbl_digits)\n",
    "print(line_s3)\n",
    "\n",
    "mapping_tbl_punc=line_s1.maketrans(string.punctuation, ' '*len(string.punctuation)) # Replace punctuation with ' ' \n",
    "print(mapping_tbl_punc)\n",
    "line_s4 = line_s3.translate(mapping_tbl_punc)\n",
    "print(line_s4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6210c2b5",
   "metadata": {},
   "source": [
    "## Task 2 \n",
    "Design a parsing function (parse_doc(input, stops)) to read a file and represent the file as a tuple\n",
    "(word_count, {docid:curr_doc})\n",
    "\n",
    "## Task 3\n",
    "Design the main function to read a xml file and common-english-words.txt (the list of stopping words), call function parse_doc(input, stops), and print the itemid (docid), the number of words (word_count) and the number of terms (len(curr_doc))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7f5fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "import string\n",
    "\n",
    "\n",
    "def parse_doc(inputpath, stop_ws):\n",
    "    coll = {}    \n",
    "    #os.chdir(inputpath)\n",
    "    myfile=open('6146.xml')\n",
    "  \n",
    "    curr_doc = {}\n",
    "    start_end = False\n",
    "    \n",
    "    file_=myfile.readlines()\n",
    "    word_count = 0 #wk3\n",
    "    for line in file_:\n",
    "        line = line.strip()\n",
    "        #print(line)\n",
    "        if(start_end == False):\n",
    "            if line.startswith(\"<newsitem \"):\n",
    "                for part in line.split():\n",
    "                    if part.startswith(\"itemid=\"):\n",
    "                        docid = part.split(\"=\")[1].split(\"\\\"\")[1]\n",
    "                        break  \n",
    "            if line.startswith(\"<text>\"):\n",
    "                start_end = True  \n",
    "        elif line.startswith(\"</text>\"):\n",
    "            break\n",
    "        else:\n",
    "            line = line.replace(\"<p>\", \"\").replace(\"</p>\", \"\")\n",
    "            line = line.translate(str.maketrans('','', string.digits)).translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
    "            line = line.replace(\"\\\\s+\", \" \")\n",
    "            for term in line.split():\n",
    "                word_count += 1 #wk3\n",
    "                term = term.lower() #wk3\n",
    "                if len(term) > 2 and term not in stop_words: #wk3\n",
    "                    try:\n",
    "                        curr_doc[term] += 1\n",
    "                    except KeyError:\n",
    "                        curr_doc[term] = 1\n",
    "    myfile.close()\n",
    "    return(word_count, {docid:curr_doc})\n",
    "    # return a tuple, the first element is the number of words in <text> and\n",
    "    # the second one is a dirctionary that includes only one pair of doc_id and a disctionary of term_frequency pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22ecbe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Task2: The return value of function parse_doc ---\n",
      "(133, {'6146': {'argentine': 1, 'bonds': 1, 'slightly': 1, 'higher': 1, 'small': 1, 'technical': 2, 'bounce': 2, 'wednesday': 1, 'amid': 1, 'low': 1, 'volume': 1, 'trader': 2, 'large': 1, 'foreign': 1, 'bank': 1, 'slight': 1, 'opening': 1, 'expect': 1, 'prices': 1, 'change': 1, 'much': 1, 'during': 1, 'session': 1, 'market': 2, 'moving': 1, 'news': 1, 'expected': 2, 'percent': 1, 'dollar': 1, 'denominated': 1, 'bocon': 1, 'previsional': 1, 'due': 2, 'rose': 2, 'argentina': 2, 'frb': 1, 'quot': 2, 'general': 1, 'uncertainty': 1, 'pointing': 1, 'events': 1, 'waiting': 1, 'including': 1, 'passage': 1, 'government': 1, 'new': 1, 'economic': 1, 'measures': 1, 'through': 1, 'congress': 1, 'now': 1, 'until': 1, 'early': 1, 'october': 1, 'addition': 1, 'traders': 1, 'awaiting': 1, 'meeting': 1, 'friday': 1, 'between': 1, 'economy': 1, 'minister': 1, 'roque': 1, 'fernandez': 1, 'international': 1, 'monetary': 1, 'fund': 1, 'delegation': 1, 'fiscal': 1, 'deficit': 1, 'axel': 1, 'bugge': 1, 'buenos': 1, 'aires': 1, 'newsroom': 1}})\n",
      "--- The outcomes of Task3 ---\n",
      "Document itemid: 6146 contains: 133 words and 75 terms\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "stopwords_f = open('common-english-words.txt', 'r') # wk3\n",
    "stop_words = stopwords_f.read().split(',')\n",
    "stopwords_f.close()\n",
    "\n",
    "x = parse_doc(\"\",stop_words)\n",
    "print('--- Task2: The return value of function parse_doc ---')\n",
    "print(x)\n",
    "print('--- The outcomes of Task3 ---')\n",
    "for doc in x[1].items():\n",
    "        print('Document itemid: '+ doc[0]+ ' contains: '+ str(x[0]) + ' words and ' + str(len(doc[1])) + ' terms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af63ba",
   "metadata": {},
   "source": [
    "Note that the solutions for task 2 and task 3 are slightly different from the .py solution. We don't need to define an explicit main function. Also, the input xml file is in the current folder, so the inputpath is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd565cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
