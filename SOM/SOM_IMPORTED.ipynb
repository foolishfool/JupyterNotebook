{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a67a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score, recall_score, precision_score\n",
    "import cv2\n",
    "from sklearn import metrics\n",
    "import newSom\n",
    "from mayavi import mlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "170bfa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringToInt(X,name):\n",
    "    X[name] = X[name].astype(str).str.strip()\n",
    "    #print(X[name])\n",
    "    for i in range(0, X.shape[0]):\n",
    "        if  X.at[i,name]== 'Jan':\n",
    "            X.at[i,name] =1            \n",
    "        elif  X.at[i,name]== 'Feb':\n",
    "                X.at[i,name]=2 \n",
    "        elif  X.at[i,name]== 'Mar': \n",
    "            X.at[i,name]=3 \n",
    "        elif  X.at[i,name]== 'Apr': \n",
    "            X.at[i,name]=4 \n",
    "        elif  X.at[i,name]== 'May': \n",
    "            X.at[i,name]=5 \n",
    "        elif  X.at[i,name]== 'June': \n",
    "            X.at[i,name]=6  \n",
    "        elif  X.at[i,name]== 'Jul': \n",
    "            X.at[i,name]=7 \n",
    "        elif  X.at[i,name]== 'Aug':\n",
    "            X.at[i,name]=8 \n",
    "        elif  X.at[i,name]== 'Sep':\n",
    "            X.at[i,name]=9 \n",
    "        elif  X.at[i,name]== 'Oct':\n",
    "            X.at[i,name]=10\n",
    "        elif  X.at[i,name]== 'Nov':\n",
    "            X.at[i,name]=11 \n",
    "        elif  X.at[i,name]== 'Dec': \n",
    "            X.at[i,name]=12\n",
    "        elif  X.at[i,name]== 'Returning_Visitor':  \n",
    "            X.at[i,name]=0\n",
    "        elif  X.at[i,name]== 'New_Visitor': \n",
    "            X.at[i,name]=1\n",
    "        elif  X.at[i,name]== 'Other': \n",
    "            X.at[i,name]=3\n",
    "        elif  X.at[i,name]== 'False': \n",
    "            X.at[i,name]=0        \n",
    "        elif  X.at[i,name]== 'True': \n",
    "            #print(X.at[i,name])\n",
    "            X.at[i,name]=1\n",
    "            #print(X.at[i,name])\n",
    "        else: \n",
    "            print(\"Unkonwn value {}\".format(X.at[i,name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1bea7976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7330, 16)\n",
      "Int64Index([    0,     2,     5,     6,     7,     8,     9,    10,    13,\n",
      "               15,\n",
      "            ...\n",
      "            12313, 12314, 12315, 12317, 12318, 12324, 12325, 12326, 12327,\n",
      "            12329],\n",
      "           dtype='int64', length=7330)\n"
     ]
    }
   ],
   "source": [
    "csv = pd.read_csv(\"online_shoppers_intention.csv\")\n",
    "del csv[\"Month\"]\n",
    "del csv[\"Weekend\"]\n",
    "stringToInt(csv,\"VisitorType\")\n",
    "stringToInt(csv,\"Revenue\")\n",
    "#sample number of train and test dataset\n",
    "train_num = 5000\n",
    "test_num = 5000\n",
    "#get samples\n",
    "data_train = csv.sample(train_num)\n",
    "\n",
    "data_test = csv.drop(data_train.index)\n",
    "print(data_test.shape)\n",
    "print(data_test.index)\n",
    "#data_train.to_numpy(dtype=np.float64)\n",
    "#data_test = csv.sample(test_num).to_numpy(dtype=np.float64)\n",
    "#\n",
    "#\n",
    "#label_train = data_train[:,data_train.shape[1]-1]\n",
    "#label_test = data_test[:,data_test.shape[1]-1]\n",
    "## delete the last column\n",
    "#data_train= data_train[:,:-1]\n",
    "#data_test= data_test[:,:-1]\n",
    "#print(label_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e691f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalizeLables(X,Y,category = 0):\n",
    "    \"\"\"\n",
    "    transfrer predcited label to match the range of true label\n",
    "    a = np.amax(X)+1,b = np.amax(Y)+1 the number of classes in X and Y\n",
    "    b= m*n,  to make it easier , to make b can be divided by a\n",
    "    category = 0 noramlize label\n",
    "    category = 1 normalize sub label\n",
    "    \"\"\"\n",
    "    div = int((np.amax(Y)+1)/(np.amax(X)+1))\n",
    "    #print(\"div : {}\".format(div) )\n",
    "    if(category == 0):\n",
    "        global nLabel \n",
    "        nLabel = np.arange(Y.size)\n",
    "    if(category == 1):\n",
    "        global nsubLabel \n",
    "        nsubLabel = np.arange(Y.size)\n",
    "    index = 0;\n",
    "    for idx, y in enumerate(Y): \n",
    "       # print(\"idx {}\".format(idx))\n",
    "        for i in range(1,div+1):\n",
    "            if(y < i*div):\n",
    "                index+=1\n",
    "                #print(i-1)\n",
    "                if(category == 0):\n",
    "                    nLabel[idx] = i-1\n",
    "                if(category == 1):\n",
    "                    nsubLabel[idx] = i-1\n",
    "                break               \n",
    "    if(category == 0):\n",
    "        print(\"normalized predicted nLabel:\\n {} \".format(nLabel))\n",
    "    if(category == 1):\n",
    "        print(\"normalized predicted nsubLabel: \\n{} \".format(nsubLabel))\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5076323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    #print(y_true.shape)\n",
    "    #print(y_pred.shape)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "   # print (np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix))\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9993a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupClusterList(m,Y):\n",
    "    \"\"\"\n",
    "    transfer all label in a list\n",
    "    m: cluster Number\n",
    "    \"\"\"\n",
    "    clusters = []\n",
    "    for i in range(0,m):\n",
    "        newlist = []\n",
    "        for idx, y in enumerate(Y): \n",
    "            if(y == i):\n",
    "                newlist.append(idx)\n",
    "        clusters.append(newlist) \n",
    "   # print(clusters)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc2ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNoisyClusters(list_true,list_pred):\n",
    "    \"\"\"\n",
    "    get the wrong data indices in the training data when predicted with weight1\n",
    "    \"\"\"\n",
    "    noisylist = []\n",
    "    for i in range(0,len(list_true)):\n",
    "        newlist = [item for item in list_pred[i] if item not in list_true[i]]\n",
    "        noisylist.append(newlist)\n",
    "    print(\"noisy data:\")\n",
    "    return noisylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a7b3461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_noisy_data(noisy_list, percent):\n",
    "    newlist = []\n",
    "    for x in noisy_list:\n",
    "        for e in x:\n",
    "            newlist.append(e)\n",
    "   # print(newlist)\n",
    "   # print(len(newlist))\n",
    "   # print(int(percent * len(newlist)))\n",
    "    newlist = random.sample(newlist, int(percent * len(newlist)))\n",
    "   # print(newlist)\n",
    "    return newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97037b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data_byindice(reduced_indices,X,category = 0):\n",
    "   \n",
    "    if(category == 0): \n",
    "        global data_train_subset\n",
    "        data_train_subset= np.delete(X, reduced_indices, axis=0)\n",
    "        #print(\"reduced_indices :{}\".format(reduced_indices))\n",
    "    if(category == 1): \n",
    "        global data_train_sublabel\n",
    "        data_train_sublabel=np.delete(X,reduced_indices, axis=0)\n",
    "    #print(df_subset.to_numpy())   \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6114245",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "som1 = newSom.SOM(m=4, n=4, dim=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "373f3384",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate weight1:\n",
      " [6.09199190e-08 1.67529777e-07 0.00000000e+00 0.00000000e+00\n",
      " 4.00000061e+00 1.07000031e+02 4.12018774e-10 5.00000000e-02\n",
      " 0.00000000e+00 5.99999991e-01 2.99999997e+00 1.99999998e+00\n",
      " 2.99999997e+00 1.29999998e+01 0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "som1.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c16ff160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights used:\n",
      "\n",
      "[6.09199190e-08 1.67529777e-07 0.00000000e+00 0.00000000e+00\n",
      " 4.00000061e+00 1.07000031e+02 4.12018774e-10 5.00000000e-02\n",
      " 0.00000000e+00 5.99999991e-01 2.99999997e+00 1.99999998e+00\n",
      " 2.99999997e+00 1.29999998e+01 0.00000000e+00]\n",
      "predicted label:\n",
      " [15 15  0 ... 15 15 11]\n"
     ]
    }
   ],
   "source": [
    "predictions1_w1 = som1.predict(data_train,som1.weights1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fe08705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalized predicted nLabel:\n",
      " [1 1 0 ... 1 1 1] \n"
     ]
    }
   ],
   "source": [
    "NormalizeLables(label_train,predictions1_w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa3c796e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8352"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "purity_score(label_train,nLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "225aff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noisy data:\n"
     ]
    }
   ],
   "source": [
    "global noisy_list\n",
    "noisy_list = getNoisyClusters(groupClusterList(2,label_train),groupClusterList(2,nLabel))\n",
    "reduced_indices = reduce_noisy_data(noisy_list,0.1)\n",
    "reduce_data_byindice(reduced_indices,data_train)\n",
    "reduce_data_byindice(reduced_indices,label_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04dad815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate weight2:\n",
      " [1.29320341e+00 7.61249965e+01 7.10222973e-02 3.55427042e+00\n",
      " 2.42463730e+01 8.33853972e+02 1.11796334e-02 4.10507765e-02\n",
      " 2.62480752e+00 2.36557765e-03 2.88220061e+00 2.04288808e+00\n",
      " 2.42665001e+00 1.92505096e+00 2.44439154e-02]\n"
     ]
    }
   ],
   "source": [
    "som1.fit(data_train_subset,weightIndex =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fede6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights used:\n",
      "\n",
      "[1.29320341e+00 7.61249965e+01 7.10222973e-02 3.55427042e+00\n",
      " 2.42463730e+01 8.33853972e+02 1.11796334e-02 4.10507765e-02\n",
      " 2.62480752e+00 2.36557765e-03 2.88220061e+00 2.04288808e+00\n",
      " 2.42665001e+00 1.92505096e+00 2.44439154e-02]\n",
      "predicted label:\n",
      " [ 3  6 12 ...  2  3  1]\n",
      "normalized predicted nsubLabel: \n",
      "[0 0 1 ... 0 0 0] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8386161176714315"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2_W2 = som1.predict(data_train_subset,som1.weights2)\n",
    "NormalizeLables(data_train_sublabel,predictions2_W2,1)\n",
    "purity_score(data_train_sublabel,nsubLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a02751e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights used:\n",
      "\n",
      "[6.09199190e-08 1.67529777e-07 0.00000000e+00 0.00000000e+00\n",
      " 4.00000061e+00 1.07000031e+02 4.12018774e-10 5.00000000e-02\n",
      " 0.00000000e+00 5.99999991e-01 2.99999997e+00 1.99999998e+00\n",
      " 2.99999997e+00 1.29999998e+01 0.00000000e+00]\n",
      "predicted label:\n",
      " [ 0  6 15 ...  4  9  0]\n",
      "normalized predicted nLabel:\n",
      " [0 0 1 ... 0 1 0] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8466"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_W1 = som1.predict(data_test,som1.weights1)\n",
    "NormalizeLables(label_test,predictions_test_W1,0)\n",
    "purity_score(label_test,nLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84b2c895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights used:\n",
      "\n",
      "[1.29320341e+00 7.61249965e+01 7.10222973e-02 3.55427042e+00\n",
      " 2.42463730e+01 8.33853972e+02 1.11796334e-02 4.10507765e-02\n",
      " 2.62480752e+00 2.36557765e-03 2.88220061e+00 2.04288808e+00\n",
      " 2.42665001e+00 1.92505096e+00 2.44439154e-02]\n",
      "predicted label:\n",
      " [12 10  3 ... 12  4 12]\n",
      "normalized predicted nLabel:\n",
      " [1 1 0 ... 1 0 1] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8466"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_test_W2 = som1.predict(data_test,som1.weights2)\n",
    "NormalizeLables(label_test,predictions_test_W2,0)\n",
    "purity_score(label_test,nLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3371ad22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
