{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56be3ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (2463741087.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    return\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "a =[0,1,2,3,4,5] \n",
    "b=[5,5,5,5,5,5]\n",
    "nmi = normalized_mutual_info_score(a,b, average_method='max')\n",
    "print (nmi)\n",
    "\n",
    "len(a)\n",
    "return  \n",
    "\n",
    "def mutual_info(c_A, c_B):\n",
    "    N_mA = len(c_A)\n",
    "    N_mB = len(c_B)\n",
    "    I_num = 0\n",
    "    for i in c_A:\n",
    "        for j in c_B:\n",
    "            n_i = len(c_A[i])\n",
    "            n_j = len(c_B[j])\n",
    "            n_ij = len(c_A[i] & c_B[j])\n",
    "            if n_ij == 0:\n",
    "                continue\n",
    "            log_term = log((n_ij * S) / (n_i * n_j))\n",
    "\n",
    "            I_num += n_ij * log_term\n",
    "    I_num *= -2\n",
    "\n",
    "    I_den = 0\n",
    "    for i in c_A:\n",
    "        n_i = len(c_A[i])\n",
    "        I_den += n_i * log(n_i / S)\n",
    "\n",
    "    for j in c_B:\n",
    "        n_j = len(c_B[j])\n",
    "        I_den += n_j * log(n_j / S)\n",
    "\n",
    "    I = I_num / I_den\n",
    "    return I\n",
    "\n",
    "mutual_info(a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f2ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9d34dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THIS CODE ONLY DO THE WHOLE DATA TRAINING, NO CROSS_VALIDATION AND FEATURE SELECTION\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import newSom \n",
    "import experiment\n",
    "import dataset_read\n",
    "import researchpy as rp\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aee060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataread = dataset_read.DATAREAD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b435e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.data_continuous_indexes ['Age']\n",
      " column number self.data_train_discrete 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fooli\\anaconda3\\lib\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\fooli\\anaconda3\\lib\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\fooli\\anaconda3\\lib\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n",
      "C:\\Users\\fooli\\anaconda3\\lib\\site-packages\\category_encoders\\base_contrast_encoder.py:126: FutureWarning: Intercept column might not be added anymore in future releases (c.f. issue #370)\n",
      "  warnings.warn(\"Intercept column might not be added anymore in future releases (c.f. issue #370)\",\n"
     ]
    }
   ],
   "source": [
    "\n",
    "csv = pd.read_csv(\"CustomerSegmentation/Train.csv\")\n",
    "csv2 = pd.read_csv(\"CustomerSegmentation/Test.csv\")\n",
    "csv = csv.drop(columns=['ID','Segmentation'])\n",
    "csv2 = csv2.drop(columns=['ID'])   \n",
    "\n",
    "csv['Family_Size'] = pd.to_numeric(csv['Family_Size'])\n",
    "csv2['Family_Size'] = pd.to_numeric(csv2['Family_Size'])\n",
    "csv['Work_Experience'] = pd.to_numeric(csv['Work_Experience'])\n",
    "csv2['Work_Experience'] = pd.to_numeric(csv2['Work_Experience'])\n",
    "\n",
    "csv_original_encode1 = csv\n",
    "csv_original_encode2 = csv2\n",
    "\n",
    "# class label do not need to onehot encoding, label ercoding will be OK\n",
    "dataread.label_encoding(csv_original_encode1,\"Var_1\")\n",
    "#one hot encoding vs proposed\n",
    "dataread.effect_encoding(csv_original_encode1,[\"Gender\",\"Ever_Married\",\"Graduated\",\"Profession\",\"Spending_Score\",\"Family_Size\",\"Work_Experience\"])\n",
    "\n",
    "\n",
    "csv_training_original_encoded = dataread.original_encoding_data.sample(int(dataread.original_encoding_data.shape[0]*0.5))\n",
    "\n",
    "\n",
    "dataread.label_encoding(csv_original_encode2,\"Var_1\")\n",
    "#one hot encoding vs proposed\n",
    "dataread.effect_encoding(csv_original_encode2,[\"Gender\",\"Ever_Married\",\"Graduated\",\"Profession\",\"Spending_Score\",\"Family_Size\",\"Work_Experience\"])\n",
    "\n",
    "#dataread.original_encoding_data is udpated through dataread.label_encoding function\n",
    "csv_test_original_encoded = dataread.original_encoding_data\n",
    "\n",
    "dataread.label_encoding(csv,\"Gender\")\n",
    "dataread.label_encoding(csv,\"Ever_Married\")\n",
    "dataread.label_encoding(csv,\"Graduated\")\n",
    "dataread.label_encoding(csv,\"Profession\")\n",
    "dataread.label_encoding(csv,\"Spending_Score\")\n",
    "dataread.label_encoding(csv,\"Var_1\")\n",
    "dataread.label_encoding(csv,\"Family_Size\")\n",
    "dataread.label_encoding(csv,\"Work_Experience\")\n",
    "\n",
    "\n",
    "\n",
    "dataread.label_encoding(csv2,\"Gender\")\n",
    "dataread.label_encoding(csv2,\"Ever_Married\")\n",
    "dataread.label_encoding(csv2,\"Graduated\")\n",
    "dataread.label_encoding(csv2,\"Profession\")\n",
    "dataread.label_encoding(csv2,\"Spending_Score\")\n",
    "dataread.label_encoding(csv2,\"Var_1\")\n",
    "dataread.label_encoding(csv2,\"Family_Size\")\n",
    "dataread.label_encoding(csv2,\"Work_Experience\")\n",
    "\n",
    "\n",
    "\n",
    "csv_training = csv.sample(int(csv.shape[0]*0.5))\n",
    "csv_test = csv2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataread.initializedataset(csv,csv_training,csv_test,csv_training_original_encoded,csv_test_original_encoded,\"Var_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb8cf14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuron unit number: 13\n",
      "mapped_class_in_clusters [[5, 1, 1, 1, 5, 5, 0, 5, 5, 5, 5, 6, 5, 7, 3, 5, 5, 5, 0, 5, 5, 2, 5, 3, 5, 3, 5, 5, 5, 5, 5, 5, 5, 2, 5, 0, 5, 1, 5, 5, 5, 5, 5, 3, 3, 5, 2, 5, 5, 5, 5, 3, 3, 1, 6, 5, 5, 5, 2, 5, 3, 5, 5, 1, 6, 3, 5, 3, 2, 5, 3, 2, 5, 2, 3, 4, 5, 5, 5, 5, 5, 3, 5, 1, 5, 5, 5, 2, 1, 5, 5, 2, 5, 7, 5, 5, 5, 5, 5, 4, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 6, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 3, 5, 3, 1, 5, 5, 2, 5, 5, 3, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 3, 3, 1, 2, 2, 6, 5, 3, 5, 5, 5, 5, 3, 5, 6, 3, 5, 5, 2, 4, 5, 5, 5, 5, 5, 3, 5, 3, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 2, 4, 5, 0, 1, 5, 5, 0, 5], [5, 5, 5, 5, 5, 5, 3, 3, 5, 5, 5, 7, 3, 1, 5, 2, 2, 5, 5, 5, 5, 5, 5, 5, 3, 3, 5, 0, 3, 2, 5, 5, 5, 5, 5, 3, 5, 5, 5, 3, 5, 5, 5, 1, 1, 5, 5, 5, 2, 5, 0, 1, 2, 2, 7, 3, 2, 5, 5, 3, 3, 1, 2, 5, 3, 5, 3, 5, 5, 5, 5, 5, 2, 5, 6, 5, 5, 2, 5, 2, 1, 5, 3, 5, 5, 4, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 1, 6, 2, 5, 3, 5, 6, 3, 5, 3, 5, 0, 5, 5, 1, 5, 3, 5, 5, 5, 5, 1, 5, 5, 6, 6, 6, 5, 5, 2, 5, 0, 5, 5, 3, 3, 5, 2, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 2, 5, 5, 5, 5, 3, 5, 5, 5, 3, 5, 1, 5, 2, 5, 5, 5, 5, 5, 5, 2, 5, 1, 5, 3, 5, 5, 6, 0, 5, 5, 1, 2, 5, 5, 3, 5, 5, 5, 1, 7, 5, 0, 5, 5, 5, 5, 5, 1, 3, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 2, 3, 5, 5, 5, 2, 1, 5, 5, 5, 5, 5, 3, 5], [5, 3, 5, 5, 5, 5, 1, 1, 5, 5, 6, 5, 5, 5, 5, 3, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 1, 5, 5, 2, 5, 5, 5, 5, 0, 7, 5, 5, 5, 5, 5, 5, 5, 2, 5, 3, 5, 6, 5, 2, 5, 6, 5, 2, 5, 2, 5, 5, 5, 5, 3, 3, 3, 5, 1, 2, 5, 5, 5, 5, 5, 5, 3, 7, 3, 3, 3, 3, 5, 5, 5, 2, 3, 5, 5, 5, 5, 6, 5, 5, 5, 3, 0, 5, 5, 3, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 6, 5, 3, 5, 1, 2, 5, 5, 5, 5, 4, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 3, 5, 5, 5, 5, 2, 5, 5, 6, 5, 5, 5, 3, 5, 5, 3, 5, 5, 3, 2, 3, 5, 3, 5, 5, 5, 1, 5, 5, 5, 5, 2, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 6, 5, 5, 5, 2, 5, 3, 5, 3, 5, 2, 5, 5, 5, 5, 3, 5, 3, 5, 6, 5, 3, 5, 7, 2, 3, 1, 2, 5, 5, 5, 5, 5, 5, 5, 2, 6, 5, 5, 5, 5, 5, 2, 5, 1, 5, 4, 3, 5, 5, 5, 5, 2, 2, 5, 5, 3, 2, 2, 1, 5, 5, 5, 5, 5, 2], [5, 3, 3, 3, 2, 3, 5, 5, 5, 2, 5, 5, 5, 5, 2, 5, 5, 5, 3, 2, 5, 5, 3, 3, 5, 5, 5, 7, 0, 0, 5, 5, 2, 5, 3, 5, 3, 6, 5, 2, 2, 1, 2, 5, 5, 5, 5, 5, 1, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 3, 5, 5, 5, 5, 5, 1, 5, 5, 2, 5, 2, 1, 5, 5, 5, 5, 5, 5, 3, 3, 5, 5, 1, 5, 6, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 1, 2, 5, 3, 5, 5, 5, 5, 6, 2, 3, 5, 5, 5, 3, 2, 2, 5, 5, 5, 5, 5, 3, 2, 5, 5, 2, 5, 5, 5, 5, 5, 5, 4, 0, 2, 5, 1, 2, 5, 1, 3, 2, 1, 4, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 1, 5, 2, 3, 4, 5, 0, 5, 5, 3, 5, 3, 5, 5, 6, 5, 5, 3, 5, 5, 1, 3, 2, 2, 3, 5, 5, 0, 5, 5, 5, 5, 5, 3, 5, 5, 2, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 2, 5, 3, 5, 3, 5, 3, 6, 5, 5, 5, 2, 5, 5, 3, 1, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 2, 5, 5], [5, 3, 4, 5, 5, 2, 5, 5, 5, 1, 1, 3, 2, 5, 5, 6, 2, 3, 5, 1, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 7, 5, 5, 7, 5, 3, 2, 5, 5, 5, 5, 0, 5, 5, 5, 3, 5, 5, 5, 5, 2, 5, 3, 6, 3, 3, 4, 3, 5, 3, 5, 5, 5, 6, 5, 2, 5, 3, 1, 2, 3, 5, 5, 5, 5, 5, 5, 5, 2, 5, 4, 5, 3, 5, 3, 6, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 1, 3, 3, 3, 2, 3, 1, 3, 5, 1, 5, 5, 3, 3, 3, 6, 2, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 2, 6, 5, 5, 2, 5, 2, 5, 2, 5, 2, 2, 3, 5, 2, 5, 5, 5, 5, 5, 5, 2, 3, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 2, 5, 5, 5, 5, 2, 5, 5, 6, 5, 0, 5, 5, 5, 5, 5, 3, 5, 5, 5, 3, 5, 5, 5, 3, 5, 5, 5, 5, 5, 3, 2, 3, 1, 3, 3, 5, 1, 5, 4, 5, 6, 3, 5, 5, 6, 5, 3, 3, 5, 5, 1, 3, 5, 5, 2, 5, 5, 3, 3, 1, 5, 5, 5, 5, 5, 5, 3, 3, 3, 5, 2, 5, 5, 3, 7, 5, 3, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 3, 1, 2, 5, 2, 5, 5, 5, 5, 5, 5, 5, 1, 5, 3, 3, 5, 5, 5, 2, 3, 5, 5, 5, 3, 5, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 4, 6, 5, 2, 3, 5, 5, 1, 5, 5, 5, 5, 3, 5, 5, 5, 3, 2, 2, 7, 5, 1, 3, 2, 5, 5, 1, 5, 5, 6, 5, 5, 2, 5, 2, 5, 2, 5, 6, 5, 2, 5, 5, 5, 5, 2, 2, 5, 2, 5, 3, 2, 2, 5, 3, 5, 5, 5, 3, 1, 5, 5, 5, 5, 4, 5, 2, 5, 2, 5, 5, 5, 3, 7, 5, 5, 5, 5, 3, 5, 5, 3, 2, 3, 5, 3, 5, 5, 5, 2, 0, 5, 5, 1, 3, 5, 1, 6, 5, 5], [5, 5, 5, 5, 5, 3, 5, 5, 5, 2, 5, 5, 3, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 2, 3, 3, 5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 3, 3, 5, 5, 5, 5, 3, 5, 5, 5, 6, 5, 5, 3, 3, 5, 5, 5, 5, 5, 3, 5, 5, 6, 2, 5, 1, 5, 1, 3, 5, 1, 5, 5, 1, 5, 5, 5, 5, 0, 5, 5, 1, 2, 5, 5, 3, 5, 5, 5, 0, 5, 5, 3, 1, 5, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 3, 5, 1, 5, 2, 5, 7, 5, 5, 5, 1, 1, 5, 5, 3, 3, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 1, 5, 5, 5, 6, 5, 3, 5, 5, 5, 5, 5, 5, 2, 2, 5, 3, 1, 6, 5, 5, 2, 5, 5, 6, 2, 5, 7, 3, 5, 5, 5, 1, 5, 5, 5, 5, 5, 1, 5, 5, 5, 6, 2, 5, 3, 5, 1, 5, 5, 5, 3, 5, 3, 5, 1, 5, 5, 5, 3, 3, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 3, 5, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 1, 5, 5, 3, 2, 5, 5, 1, 5, 3, 3, 3, 5, 5, 5, 5, 0, 5, 2, 5, 5, 5, 5, 2, 2, 5, 5, 3, 5, 5, 2, 5, 5, 7, 5, 5, 2, 3, 5, 5, 2, 5, 5, 5, 4, 2, 3, 3, 6, 5, 5, 3, 3, 3, 3, 2, 3, 2, 6, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 0, 3, 5, 3, 5, 5, 5, 5, 5, 3, 5, 2, 4, 5, 3, 5, 2, 5, 2], [5, 2, 5, 5, 3, 5, 2, 1, 5, 5, 5, 2, 5, 5, 5, 3, 5, 3, 5, 7, 2, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 7, 3, 5, 6, 5, 5, 5, 1, 5, 5, 5, 5, 2, 5, 5, 4, 1, 5, 3, 3, 2, 1, 5, 5, 5, 2, 4, 5, 3, 5, 5, 5, 5, 3, 5, 2, 5, 5, 5, 2, 5, 5, 5, 1, 6, 3, 2, 1, 5, 5, 5, 5, 5, 5, 5, 6, 6, 5, 5, 3, 6, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 3, 2, 5, 2, 5, 4, 5, 3, 5, 5, 5, 5, 5, 5, 5, 3, 3, 5, 5, 3, 5, 5, 3, 2, 5, 5, 3, 5, 5, 5, 2, 3, 2, 5, 5, 5, 3, 3, 2, 0, 3, 5, 5, 5, 2, 5, 7, 3, 5, 1, 5, 3, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 1, 2, 5, 5, 5, 5, 5, 5, 5, 1, 3, 5, 1, 5, 5, 5, 5, 5, 1, 7, 5, 3, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 2, 5, 5, 0, 1, 5, 5, 3, 3, 5, 5, 2, 0, 5, 5, 5, 5, 1, 2, 5, 5, 3, 5, 5, 5, 5, 5, 5, 3, 5, 5, 6, 5, 5, 5, 5, 7, 3, 0, 5, 5, 4, 5, 4, 5, 5, 5, 5, 5, 3, 5, 3, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 2, 5, 3, 5, 5, 3, 6, 2, 5, 3, 5, 2, 5, 4, 0, 5, 5, 5, 5, 5, 5, 2, 2, 3, 3, 1, 6, 5, 5, 2, 2, 5, 5, 5, 2, 3, 1, 3, 5, 4, 5, 5, 5, 5, 1, 5], [5, 5, 5, 3, 5, 5, 5, 5, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 7, 1, 5, 5, 2, 2, 5, 3, 3, 2, 5, 5, 5, 3, 5, 5, 3, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 2, 0, 7, 5, 2, 5, 2, 3, 3, 5, 5, 2, 5, 5, 3, 2, 5, 2, 5, 1, 5, 3, 5, 5, 5, 3, 5, 5, 5, 5, 1, 3, 3, 5, 3, 5, 0, 5, 3, 5, 3, 4, 5, 3, 2, 1, 5, 1, 5, 1, 5, 6, 3, 5, 5, 2, 5, 5, 5, 5, 5, 5, 1, 3, 1, 5, 5, 5, 5, 5, 7, 5, 7, 5, 5, 5, 5, 3, 5, 5, 5, 3, 5, 3, 2, 1, 5, 3, 5, 2, 5, 3, 3, 2, 5, 2, 5, 3, 5, 3, 6, 5, 2, 5, 5, 5, 5, 5, 5, 7, 3, 5, 2, 5, 5, 5, 3, 5, 5, 5, 2, 5, 5, 7, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 2, 5, 5, 5, 5, 2, 5, 5, 5, 2, 5, 0, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 2, 1, 5, 2, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 2, 3, 5, 6, 3, 5, 5, 5, 2, 3, 3, 4, 5, 3, 5, 5, 2, 5, 5, 5, 5, 5, 5, 3, 1, 5, 2, 5, 2, 1, 5, 5, 5, 5, 5, 3, 5, 6, 3, 5, 5, 5, 5, 2, 5, 6, 5, 5, 5, 5, 1, 0, 6, 5, 5, 3, 5, 5, 3, 5, 5, 5, 2, 1, 2, 5, 0, 5, 5, 5, 5, 2, 5, 0, 3, 1, 2, 5, 5, 5, 2, 5, 2, 2, 5, 3, 5, 5, 5, 2, 3, 5, 3], [5, 5, 6, 5, 5, 5, 6, 1, 5, 5, 5, 5, 5, 5, 5, 3, 3, 5, 5, 5, 5, 0, 5, 5, 1, 1, 5, 5, 5, 5, 1, 2, 5, 6, 6, 5, 1, 6, 3, 5, 5, 5, 1, 2, 3, 5, 5, 5, 5, 3, 5, 5, 3, 2, 3, 5, 3, 0, 3, 2, 2, 3, 5, 5, 2, 5, 5, 1, 3, 3, 3, 5, 5, 3, 5, 1, 5, 5, 5, 3, 5, 0, 5, 5, 5, 5, 3, 5, 5, 2, 5, 2, 5, 2, 5, 5, 5, 2, 5, 2, 5, 5, 5, 3, 5, 5, 5, 1, 5, 5, 2, 3, 3, 3, 5, 5, 5, 3, 5, 5, 5, 5, 5, 0, 6, 5, 5, 5, 3, 3, 5, 3, 5, 5, 5, 5, 3, 3, 5, 0, 5, 5, 5, 5, 2, 5, 5, 5, 5, 1, 2, 5, 5, 5, 5, 3, 5, 2, 5, 1, 5, 2, 0, 5, 5, 5, 5, 5, 3, 5, 2, 5, 3, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 2, 2, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 3, 5, 2, 5, 6, 5, 5, 3, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 1, 7, 2, 5, 5, 5, 2, 1, 5, 5, 3, 5, 3, 5, 5, 5, 5, 5, 2, 3, 2, 5, 5, 5, 3, 5, 5, 5, 5, 5, 2, 5, 5, 1, 5, 2, 5, 5, 5, 1, 5, 6, 3, 5, 5, 5, 3, 1, 5, 5, 3, 5, 5, 5, 2, 5, 2, 5, 1, 5, 3, 3, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 2, 1, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 0, 5, 1, 5, 1, 5, 2, 6, 4, 5, 5, 5, 3, 1, 2, 6, 5, 3, 5, 5, 3, 3, 5, 2, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 2, 5, 0, 5, 5, 2, 5, 5, 1, 5, 5, 5, 5, 5, 2, 5, 5, 5, 3, 3, 5, 5], [2, 1, 5, 5, 2, 5, 3, 5, 6, 3, 5, 5, 5, 5, 5, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 3, 3, 5, 5, 3, 2, 5, 5, 5, 3, 0, 5, 5, 2, 5, 3, 5, 2, 7, 5, 3, 2, 5, 5, 5, 5, 5, 5, 2, 5, 5, 4, 1, 1, 5, 5, 1, 5, 5, 2, 5, 5, 6, 5, 0, 3, 3, 5, 5, 5, 3, 1, 2, 5, 5, 5, 5, 5, 4, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 2, 1, 5, 3, 5, 2, 7, 5, 5, 1, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 6, 5, 5, 5, 5, 3, 1, 5, 4, 5, 5, 1, 5, 5, 6, 1, 3, 5, 2, 2, 3, 5, 4, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 3, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 3, 5, 5, 3, 3, 5, 3, 6, 5, 5, 5, 1, 6, 5, 4, 2, 5, 5, 3, 3, 3, 5, 3, 5, 5, 3, 5, 5, 5, 5, 5, 2, 5, 3, 2, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 2, 5, 5, 1, 3, 5, 5, 5, 5, 3, 5, 5, 1, 3, 5, 3, 3, 5, 5, 5, 5, 5, 5, 0, 3, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 3, 5, 1, 6, 5, 5, 5, 5, 2, 2, 5, 5, 5, 5, 2, 5, 5, 0, 5, 5, 1, 5, 5, 5, 1, 1, 5, 1, 5, 1, 5, 7, 5, 2, 3, 1, 3, 5, 5, 5, 5, 5, 2, 3, 5, 5, 5, 3, 5, 2, 5, 7, 5, 5, 5, 5, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 3, 5, 3, 5, 5, 3, 5, 5, 5, 5, 5, 5, 0, 3], [5, 5, 5, 5, 1, 5, 5, 3, 5, 5, 3, 2, 3, 3, 3, 7, 0, 5, 1, 4, 2, 5, 2, 3, 3, 5, 5, 5, 5, 7, 5, 5, 3, 3, 5, 5, 5, 3, 5, 5, 5, 5, 1, 0, 5, 5, 2, 5, 2, 5, 5, 2, 5, 5, 5, 3, 5, 1, 5, 5, 3, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 0, 6, 5, 5, 5, 5, 1, 5, 2, 5, 5, 5, 3, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 6, 2, 5, 5, 5, 5, 3, 2, 0, 5, 6, 5, 5, 0, 5, 5, 5, 5, 4, 3, 5, 5, 5, 5, 5, 1, 3, 1, 5, 4, 5, 5, 5, 2, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 2, 5, 3, 5, 5, 5, 5, 5, 1, 1, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 3, 6, 5, 2, 5, 2, 5, 5, 5, 5, 1, 6, 5, 2, 5, 5, 3, 5, 6, 3, 5, 5, 5, 5, 5, 5, 6, 1, 5, 3, 3, 5, 6, 2, 5, 6, 2, 3, 5, 2, 3, 5, 5, 5, 5, 5, 5, 5, 1, 4, 3, 2, 3, 3, 5, 5, 2, 5, 5, 5, 2, 2, 5, 3, 5, 5, 5, 3, 2, 3, 5, 5, 2, 3, 2, 5, 5, 5, 5, 5, 3, 5, 4, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 2, 2, 5, 1, 3, 5, 3, 5, 5, 2, 5, 0, 5, 5, 1, 5, 5, 5, 5, 3, 5, 5, 2, 5, 5, 5, 5, 5, 2, 1, 5, 5, 5, 3, 5, 3, 3, 5, 5, 5, 5, 5, 2, 2, 0, 5, 1, 5, 5, 5, 5, 5, 2, 2, 3, 5, 5, 3, 5, 5, 5, 5, 5, 1, 5, 5, 3, 5, 5, 5, 1, 1, 5, 5, 3, 5, 5, 2, 5, 5, 2, 5, 7, 3, 2, 5, 5, 5, 5, 2, 5, 5, 1, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 0, 1, 5, 5, 2, 5, 5, 2, 5, 5, 5, 5, 1, 3], [5, 5, 5, 2, 4, 5, 1, 5, 5, 5, 5, 1, 5, 4, 5, 3, 5, 3, 3, 5, 1, 2, 5, 6, 3, 5, 5, 5, 3, 5, 1, 5, 2, 5, 2, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 3, 2, 5, 5, 5, 3, 2, 5, 2, 3, 5, 5, 5, 1, 5, 5, 5, 5, 5, 2, 5, 5, 3, 2, 5, 2, 2, 1, 5, 2, 5, 0, 3, 5, 5, 5, 5, 5, 5, 5, 0, 7, 5, 5, 5, 5, 3, 3, 5, 5, 6, 3, 3, 5, 5, 2, 5, 1, 5, 5, 5, 6, 5, 5, 3, 5, 5, 3, 2, 3, 5, 5, 5, 2, 5, 3, 0, 5, 5, 2, 5, 5, 5, 5, 3, 5, 5, 5, 5, 2, 2, 2, 1, 5, 5, 5, 3, 5, 3, 5, 6, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 2, 5, 5, 5, 6, 3, 6, 5, 5, 1, 5, 5, 3, 5, 5, 3, 0, 3, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 2, 5, 5, 5, 5, 3, 3, 2, 5, 3, 5, 2, 1, 5, 1, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 3, 5, 5, 3, 3, 5, 2, 2, 1, 3, 3, 5, 5, 5, 1, 5, 2, 5, 5, 5, 5, 2, 5, 3, 5, 3, 5, 5, 2, 5, 5, 5, 5, 5, 4, 3, 5, 2, 3, 5, 5], [2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 0, 5, 2, 3, 5, 5, 5, 1, 5, 5, 5, 5, 5, 2, 2, 5, 5, 3, 5, 3, 5, 5, 5, 6, 5, 2, 5, 6, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 2, 2, 7, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 1, 3, 3, 3, 5, 5, 3, 5, 5, 0, 5, 5, 5, 1, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 3, 5, 7, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 1, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 4, 5, 5, 5, 2, 5, 6, 2, 3, 3, 5, 4, 5, 3, 6, 5, 5, 5, 3, 2, 2, 5, 5, 5, 6, 3, 1, 5, 1, 5, 2, 2, 5, 2, 2, 1, 3, 3, 3, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 3, 5, 5, 3, 5, 5, 5, 3, 5, 5, 5, 5, 2, 5, 5, 2, 5, 5, 3, 2, 5, 5, 1, 5, 3, 1, 2, 3, 5, 3, 5, 2, 5, 5, 0, 5, 5, 5, 3, 5, 0, 5, 5, 7, 6, 5, 5, 5, 2, 5, 5, 5, 5, 3, 5, 1, 0, 3, 1, 5, 5, 1, 5, 3, 3, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 3, 6, 5, 5, 5, 5, 5, 3, 5, 2, 5, 5, 3, 1, 5, 5, 5, 3, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 7, 5, 4, 5, 1, 5, 5, 5, 5, 2, 4, 2, 1, 5, 3, 5, 5, 6, 5, 5, 0, 2, 3, 5, 3, 5, 5, 5, 2, 5, 5, 5, 0, 5, 1, 3, 2, 3, 0, 6, 5, 5, 0]]\n",
      "predicted_cluster_labels [5 4 2 ... 5 4 5] PLable_TLabel_Mapping [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5] \n",
      "train_discrete_score_W0_p 0.6370847793753098\n",
      " nmi y_true[5 5 5 ... 5 5 2] unique[0 1 2 3 4 5 6 7] y_pred [5 5 5 ... 5 5 5] unique [5]\n",
      "train_discrete_score_W0_n 0.0\n",
      "train_discrete_score_W0_a  0.0\n",
      "mapped_class_in_clusters [[5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 2, 5, 5, 1, 5, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 3, 5, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 3, 5, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 5, 5, 5, 5, 7, 5, 3, 5, 5, 5, 3, 5, 5, 5, 2, 0, 2, 5, 5, 5, 2, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 0, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 3, 3, 6, 6, 5, 5, 5, 5, 7, 3, 5, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 6, 5, 5, 5], [5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 4, 5, 3, 5, 3, 2, 2, 5, 2, 5, 5, 2, 2, 2, 6, 3, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 1, 6, 5, 1, 3, 5, 5, 5, 5, 5, 5, 5, 5, 1, 3, 5, 5, 5, 5, 5, 2, 5, 2, 5, 5, 5, 5, 7, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 2, 5, 6, 2, 3, 5, 2, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 5, 5, 5, 2, 2, 5, 5, 2, 5, 2, 5, 2, 5, 5, 5, 5, 5, 5, 4, 2, 5, 5, 5, 1, 3, 3, 2, 5, 5, 3, 5, 5, 3, 5, 2, 5, 5, 5, 2, 2, 5, 5, 5, 5, 3, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 3, 3, 3, 5, 5, 5, 5, 6, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 3, 5, 5, 2, 2, 5, 5, 1, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 7, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 2, 2, 5, 2, 2, 5, 5, 5, 5, 5, 5, 3, 5, 3, 2, 2, 2, 2, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 2, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 1, 5, 6, 5, 3, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 3, 3, 3, 7, 5, 5, 3, 5, 5, 5, 5, 5, 5, 5, 3, 5, 3, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 7, 2, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 5, 2, 5, 1, 3, 3, 2, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 3, 5, 5, 5, 5, 3, 5, 6, 5, 6, 2, 2, 5, 2, 5, 5, 3, 3, 5, 5, 5, 5, 3, 5, 5, 5, 5, 5, 7, 2, 5, 5, 5, 1, 1, 1, 4, 1, 5, 5, 2, 5, 2, 4, 5, 5, 5, 3, 5, 5, 5, 5, 5, 2, 3, 5, 5, 1, 5, 5, 3, 5, 0, 5, 5, 5, 5, 1, 3, 2, 5, 1, 5, 5, 5, 5, 5], [3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 3, 5, 5, 5, 5, 5, 4, 5, 5, 5, 7, 1, 5, 5, 3, 5, 2, 3, 5, 7, 5, 5, 5, 5, 5, 6, 5, 5, 0, 5, 5, 5, 2, 2, 5, 5, 2, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 6, 1, 5, 5, 2, 5, 5, 5, 3, 5, 5, 5, 5, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 2, 3, 3, 5, 5, 5, 5, 5, 2, 5, 3, 5, 5, 5, 5, 2, 5, 5, 5, 3, 6, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 3, 1, 5, 5, 1, 1, 5, 3, 3, 3, 3, 3, 3, 5, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 2, 5, 5, 5, 5, 2, 3, 2, 5, 5, 0, 3, 3, 5, 5, 3, 2, 5, 7, 5, 2, 5, 5, 1, 5, 5, 3, 1, 1, 3, 5, 2, 2, 3, 2, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 0, 5, 0, 5, 5, 7, 6, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 1, 3], [2, 7, 3, 5, 3, 5, 5, 2, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 1, 5, 5, 5, 5, 3, 5, 3, 3, 2, 5, 2, 0, 2, 5, 5, 5, 5, 5, 5, 5, 5, 1, 1, 1, 5, 5, 1, 1, 3, 5, 5, 5, 5, 3, 1, 5, 5, 3, 3, 3, 3, 5, 5, 5, 1, 5, 5, 3, 3, 3, 3, 5, 0, 5, 2, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 2, 5, 2, 2, 5, 2, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 3, 5, 5, 1, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 0, 2, 5, 5, 5, 5, 3, 3, 2, 5, 2, 5, 5, 3, 3, 5, 3, 5, 5, 5, 6, 5, 5, 5, 2, 5, 3, 3, 2, 2, 2, 5, 5, 5, 5, 5, 6, 5, 5, 2, 2, 5, 5, 3, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 2, 5, 5, 2, 5, 5, 5, 6], [5, 3, 5, 5, 5, 5, 3, 5, 5, 6, 5, 5, 5, 5, 2, 1, 5, 5, 2, 5, 5, 7, 6, 5, 5, 5, 5, 2, 0, 2, 2, 5, 5, 1, 3, 5, 2, 5, 5, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 6, 5, 5, 1, 5, 1, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 3, 5, 5, 5, 5, 5, 3, 3, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 2, 5, 2, 5, 1, 1, 3, 2, 5, 5, 5, 5, 4, 5, 5, 5, 1, 5, 5, 5, 7, 5, 5, 1, 4, 5, 5, 5, 5, 1, 5, 5, 3, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 1, 5, 5, 5, 5, 3, 5, 5, 3, 5, 5, 3, 1, 5, 6, 2, 5, 5, 3, 0, 2, 3, 1, 3, 5, 5, 5, 5, 5, 5, 5, 6, 5, 3, 5, 5, 3, 3, 1, 3, 5, 5, 5, 3, 5, 5, 5, 5, 3, 1, 5, 6, 5, 5, 5, 3, 5, 0, 1, 5, 5, 5, 5, 5, 1, 5, 3, 5], [5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 1, 5, 6, 5, 5, 0, 5, 5, 3, 6, 5, 5, 5, 3, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 6, 5, 5, 5, 6, 2, 5, 5, 5, 2, 3, 2, 2, 2, 2, 2, 2, 2, 5, 5, 5, 5, 3, 2, 2, 2, 2, 5, 3, 6, 5, 6, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 0, 1, 5, 5, 3, 3, 5, 2, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 1, 5, 5, 3, 1, 5, 3, 5, 1, 0, 3, 3, 1, 4, 5, 5, 0, 1, 5, 5, 5, 5, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 3, 6, 1, 5, 3, 3, 3, 5, 5, 1, 2, 5, 5, 5, 2, 5, 5, 5, 3, 3, 5, 5, 1, 5, 5, 5, 5, 5, 1, 2, 3, 5, 5, 2, 5, 5, 5, 2, 2, 3, 5, 3, 5, 5, 6, 3, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 3, 2, 3, 5, 5, 5, 5, 5], [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 6, 5, 2, 2, 3, 2, 5, 2, 2, 3, 3, 2, 5, 1, 2, 2, 2, 2, 1, 5, 5, 4, 3, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 5, 5, 1, 1, 5, 5, 5, 5, 5, 6, 3, 5, 5, 5, 5, 5, 5, 6, 5, 3, 5, 5, 5, 3, 5, 3, 3, 3, 3, 3, 7, 3, 5, 1, 2, 5, 4, 0, 4, 5, 5, 2, 5, 4, 1, 5, 2, 3, 5, 3, 5, 6, 5, 5, 5, 5, 3, 1, 3, 3, 5, 3, 3, 5, 5, 5, 1, 3, 5, 1, 5, 5, 5, 4, 3, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 7, 3, 5, 5, 5, 5, 3, 1, 4, 5, 2, 2, 5, 5, 3, 3, 5, 3, 0, 5, 2, 3, 3, 5, 5, 3, 5, 2, 5, 7, 3, 3, 3, 5, 5, 3, 2, 5, 5, 6, 4, 5, 3, 1, 5, 5, 5, 5, 5, 5, 6, 5, 5], [2, 5, 3, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 1, 2, 5, 2, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 2, 2, 2, 3, 2, 2, 3, 5, 2, 3, 2, 5, 5, 6, 2, 2, 2, 2, 2, 5, 5, 5, 5, 5, 3, 3, 3, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 3, 5, 5, 5, 6, 4, 5, 3, 5, 5, 5, 3, 7, 5, 5, 5, 5, 3, 2, 3, 3, 3, 5, 5, 5, 5, 5, 2, 5, 5, 0, 5, 5, 4, 5, 2, 5, 2, 2, 5, 3, 2, 5, 3, 3, 2, 1, 5, 2, 5, 3, 5, 5, 5, 5, 6, 5, 3, 2, 5, 1, 5, 5, 5, 7, 3, 5, 4, 5, 5, 5, 3, 5, 1, 3, 5, 7, 6, 5, 5, 0, 5, 3, 3, 5, 5, 5, 5, 4, 5, 5, 1, 5, 5, 3, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 1, 5, 4, 5, 5, 1, 5, 1, 1, 2, 1, 2, 3, 3, 2, 5, 3, 3, 3, 3, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 2, 5, 5, 3, 5, 3, 2, 1, 5, 3, 5, 1, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 3, 5, 3, 5, 5, 5, 0, 1, 1, 5], [5, 5, 5, 5, 5, 7, 5, 3, 5, 6, 5, 5, 2, 3, 2, 5, 1, 1, 5, 5, 6, 5, 2, 2, 2, 2, 2, 2, 2, 2, 5, 2, 6, 3, 4, 5, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 5, 5, 5, 6, 5, 5, 3, 5, 5, 5, 1, 5, 5, 3, 5, 3, 2, 3, 3, 5, 5, 5, 4, 3, 2, 3, 5, 0, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 7, 5, 2, 7, 2, 5, 5, 6, 5, 5, 5, 5, 2, 5, 5, 1, 5, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 5, 5, 5, 5, 3, 3, 3, 3, 3, 5, 5, 3, 5, 5, 0, 1, 5, 3, 2, 5, 3, 3, 5, 5, 5, 2, 6, 1, 5, 5, 2, 3, 3, 6, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 3, 2, 3, 5, 5, 1, 5, 5, 5], [5, 5, 5, 5, 5, 2, 5, 1, 5, 1, 3, 5, 0, 5, 5, 5, 3, 5, 0, 5, 5, 5, 5, 3, 5, 1, 5, 1, 1, 1, 5, 2, 2, 2, 2, 2, 2, 2, 6, 2, 2, 5, 5, 2, 2, 5, 5, 5, 5, 0, 3, 2, 3, 3, 0, 2, 3, 3, 5, 2, 2, 3, 1, 5, 5, 1, 5, 5, 1, 5, 5, 5, 1, 3, 5, 7, 6, 5, 5, 3, 5, 5, 0, 3, 3, 3, 3, 5, 5, 5, 5, 5, 3, 1, 5, 3, 3, 5, 5, 5, 5, 4, 5, 2, 5, 5, 5, 5, 3, 6, 5, 5, 1, 5, 2, 4, 2, 1, 5, 5, 3, 3, 5, 5, 7, 1, 4, 1, 1, 5, 5, 3, 5, 5, 6, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 5, 5, 1, 2, 6, 3, 3, 5, 1, 5, 5, 1, 3, 2, 2, 3, 5, 3, 5, 5, 1, 3, 1, 1, 1, 1, 3, 3, 2, 2, 2, 5, 7, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5, 2, 2, 5, 5, 5, 3, 1, 2, 5, 5, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 6, 5, 5, 5, 5, 3]]\n",
      "predicted_cluster_labels [8 8 1 ... 4 5 6] PLable_TLabel_Mapping [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5] \n",
      "test_discrete_score_W0_p 0.6364674533688618\n",
      " nmi y_true[5 5 5 ... 5 3 6] unique[0 1 2 3 4 5 6 7] y_pred [5 5 5 ... 5 5 5] unique [5]\n",
      "test_discrete_score_W0_n 0.0\n",
      "test_discrete_score_W0_a 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m interval \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m     11\u001b[0m experiment \u001b[38;5;241m=\u001b[39m experiment\u001b[38;5;241m.\u001b[39mExperiment()\n\u001b[1;32m---> 12\u001b[0m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUTtest_Discrete_Continuous\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataread\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mclass_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbest_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscope_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43munstable_repeat_num\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43minterval\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\JupyterDoc\\SOM\\experiment.py:306\u001b[0m, in \u001b[0;36mExperiment.UTtest_Discrete_Continuous\u001b[1;34m(self, dataread, noralimized, class_num, best_num, neuron_scope_num, unstable_repeat_num, type, interval, test_type, compareType)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m y \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m neuron_scope_num:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneuron unit number: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y))           \n\u001b[1;32m--> 306\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInitializedExperimentDataList\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mdataread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mnoralimized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m                        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mall_train_score_W0_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mall_train_score_W_combine_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_score_W0_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_score_W_combine_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mall_train_score_W0_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mall_train_score_W_combine_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_score_W0_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_score_W_combine_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mall_train_score_W0_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mall_train_score_W_combine_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_score_W0_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_score_W_combine_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrain_discrete_score_W0_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrain_discrete_score_W_discrete_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_discrete_score_W0_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_discrete_score_W_discrete_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrain_discrete_score_W0_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrain_discrete_score_W_discrete_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_discrete_score_W0_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_discrete_score_W_discrete_n\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrain_discrete_score_W0_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrain_discrete_score_W_discrete_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_discrete_score_W0_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_discrete_score_W_discrete_a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcompareType\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m)\u001b[49m        \n\u001b[0;32m    337\u001b[0m     y \u001b[38;5;241m=\u001b[39my \u001b[38;5;241m+\u001b[39m interval\n\u001b[0;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(y\u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m neuron_scope_num):\n",
      "File \u001b[1;32mC:\\JupyterDoc\\SOM\\experiment.py:197\u001b[0m, in \u001b[0;36mExperiment.InitializedExperimentDataList\u001b[1;34m(self, dataread, continuous_features_noralimized, y, all_train_score_W0_p, all_train_score_W_combine_p, test_score_W0_p, test_score_W_combine_p, all_train_score_W0_n, all_train_score_W_combine_n, test_score_W0_n, test_score_W_combine_n, all_train_score_W0_a, all_train_score_W_combine_a, test_score_W0_a, test_score_W_combine_a, train_discrete_score_W0_p, train_discrete_score_W_discrete_p, test_discrete_score_W0_p, test_discrete_score_W_discrete_p, train_discrete_score_W0_n, train_discrete_score_W_discrete_n, test_discrete_score_W0_n, test_discrete_score_W_discrete_n, train_discrete_score_W0_a, train_discrete_score_W_discrete_a, test_discrete_score_W0_a, test_discrete_score_W_discrete_a, iscontinous_data_test, compareType)\u001b[0m\n\u001b[0;32m    195\u001b[0m     optimize_W\u001b[38;5;241m.\u001b[39mdo_COSOM(optimize_W\u001b[38;5;241m.\u001b[39msom_discrete_original,optimize_W\u001b[38;5;241m.\u001b[39mdata_train_discrete_normalized, optimize_W\u001b[38;5;241m.\u001b[39mdata_train_discrete_unnormalized, optimize_W\u001b[38;5;241m.\u001b[39mdata_test_discrete_normalized,optimize_W\u001b[38;5;241m.\u001b[39mdata_test_discrete_unnormalized,iscontinous_data_test,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compareType \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m: \u001b[38;5;66;03m#discrete unnormalization\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m      \u001b[43moptimize_W\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_DOSOM\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compareType \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m: \u001b[38;5;66;03m# hybrid embedding continous + discrete_embedding\u001b[39;00m\n\u001b[0;32m    199\u001b[0m      optimize_W\u001b[38;5;241m.\u001b[39mdo_CDOSOM()    \n",
      "File \u001b[1;32mC:\\JupyterDoc\\SOM\\CDSOM.py:1180\u001b[0m, in \u001b[0;36mCDSOM.do_DOSOM\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;66;03m#print(f\"self.training_new_embedding  {self.discrete_data_embedding.shape} \" )\u001b[39;00m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;66;03m# new som neuron number is not changed, m,n not change\u001b[39;00m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msom_newEmbedding \u001b[38;5;241m=\u001b[39m newSom\u001b[38;5;241m.\u001b[39mSOM(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msom_discrete_original_encoder\u001b[38;5;241m.\u001b[39mweights0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] , \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msom_discrete_original_encoder\u001b[38;5;241m.\u001b[39mweights0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],dim) \n\u001b[1;32m-> 1180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msom_newEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscrete_data_embedding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1181\u001b[0m weight_newEmbedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msom_newEmbedding\u001b[38;5;241m.\u001b[39mweights0\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_W_newembedding_predicted_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msom_newEmbedding\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiscrete_data_embedding,weight_newEmbedding)    \n",
      "File \u001b[1;32mC:\\JupyterDoc\\SOM\\newSom.py:368\u001b[0m, in \u001b[0;36mSOM.fit\u001b[1;34m(self, X, weightIndex, epochs, shuffle, showlog)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m X[idx]\n\u001b[0;32m    365\u001b[0m \u001b[38;5;66;03m#if (type(input) is np.float64):\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;66;03m#    input = [input]\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;66;03m# Do one step of training\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mshowlog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# Update learning rate\u001b[39;00m\n\u001b[0;32m    370\u001b[0m global_iter_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mC:\\JupyterDoc\\SOM\\newSom.py:208\u001b[0m, in \u001b[0;36mSOM.step\u001b[1;34m(self, x, showlog)\u001b[0m\n\u001b[0;32m    204\u001b[0m local_multiplier \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack([local_step]\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;66;03m#print(\"local_multiplier:{}\".format(local_multiplier))\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# Multiply by difference between input and weights\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m#print(\"delta:{}\".format(delta))\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m delta \u001b[38;5;241m=\u001b[39m local_multiplier \u001b[38;5;241m*\u001b[39m (\u001b[43mx_stack\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m#print(\"delta:{}\".format(delta))\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;66;03m#print(\"weights:{}\".format(self.weights))\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# Update weights\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m delta\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#onhot encoding vs proposed\n",
    "import experiment\n",
    "unstable_repeat_num= 30\n",
    "scope_num = 80\n",
    "class_num = 13\n",
    "dim_num = 7\n",
    "best_num = 48\n",
    "interval = 3\n",
    "\n",
    "\n",
    "experiment = experiment.Experiment()\n",
    "experiment.UTtest_Discrete_Continuous(dataread,False,class_num,best_num, scope_num,unstable_repeat_num,0,interval,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9115d60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#softmax vs original\n",
    "import experiment\n",
    "unstable_repeat_num= 30\n",
    "scope_num = 80\n",
    "class_num = 13\n",
    "dim_num = 7\n",
    "best_num = 48\n",
    "interval = 3\n",
    "\n",
    "\n",
    "experiment = experiment.Experiment()\n",
    "experiment.UTtest_Discrete_Continuous(dataread,False,class_num,best_num, scope_num,unstable_repeat_num,0,interval,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c598616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#comparision softmax\n",
    "import experiment\n",
    "unstable_repeat_num= 30\n",
    "scope_num = 80\n",
    "class_num = 13\n",
    "dim_num = 7\n",
    "best_num = 48\n",
    "interval = 3\n",
    "\n",
    "\n",
    "experiment = experiment.Experiment()\n",
    "experiment.UTtest_Discrete_Continuous(dataread,False,class_num,best_num, scope_num,unstable_repeat_num,0,interval,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe99668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiment\n",
    "unstable_repeat_num= 30\n",
    "scope_num = 80\n",
    "class_num = 13\n",
    "dim_num = 7\n",
    "best_num = 48\n",
    "interval = 3\n",
    "\n",
    "\n",
    "experiment = experiment.Experiment()\n",
    "experiment.UTtest_Discrete_Continuous(dataread,class_num,best_num, scope_num,unstable_repeat_num,0,interval,2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef1418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiment\n",
    "unstable_repeat_num= 30\n",
    "scope_num = 80\n",
    "class_num = 13\n",
    "dim_num = 7\n",
    "best_num = 48\n",
    "interval = 3\n",
    "\n",
    "\n",
    "experiment = experiment.Experiment()\n",
    "experiment.UTtest_Discrete_Continuous(dataread,class_num,best_num, scope_num,unstable_repeat_num,0,interval,False,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ea708",
   "metadata": {},
   "outputs": [],
   "source": [
    "import experiment\n",
    "unstable_repeat_num= 30\n",
    "scope_num = 80\n",
    "class_num = 13\n",
    "dim_num = 7\n",
    "best_num = 48\n",
    "interval = 3\n",
    "\n",
    "\n",
    "experiment = experiment.Experiment()\n",
    "experiment.UTtest_Discrete_Continuous(dataread,class_num,best_num, scope_num,unstable_repeat_num,0,interval,False,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a10071c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import experiment\n",
    "unstable_repeat_num= 30\n",
    "scope_num = 100\n",
    "class_num = 13\n",
    "dim_num = 7\n",
    "best_num = 48\n",
    "interval = 5\n",
    "\n",
    "\n",
    "experiment = experiment.Experiment()\n",
    "experiment.UTtest_Discrete_Continuous(dataread,class_num,best_num, scope_num,unstable_repeat_num,0,interval,True,0)\n",
    "experiment.UTtest_Discrete_Continuous(dataread,class_num,best_num, scope_num,unstable_repeat_num,0,interval,True,1)\n",
    "experiment.UTtest_Discrete_Continuous(dataread,class_num,best_num, scope_num,unstable_repeat_num,0,interval,True,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27eb5dd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import experiment\n",
    "unstable_repeat_num= 30\n",
    "scope_num = 100\n",
    "class_num = 13\n",
    "dim_num = 7\n",
    "best_num = 48\n",
    "interval = 5\n",
    "\n",
    "\n",
    "experiment = experiment.Experiment()\n",
    "experiment.UTtest_Discrete_Continuous(dataread,class_num,best_num, scope_num,unstable_repeat_num,0,interval,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b5134a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import experiment\n",
    "unstable_repeat_num= 30\n",
    "scope_num = 200\n",
    "class_num = 4\n",
    "dim_num = 7\n",
    "best_num = 48\n",
    "interval = 5\n",
    "\n",
    "\n",
    "experiment = experiment.Experiment()\n",
    "experiment.UTtest_Discrete_Continuous(dataread,class_num,best_num, scope_num,unstable_repeat_num,0,interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3cedfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6811430c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
